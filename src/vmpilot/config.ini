# VMPilot Configuration File

[general]
# Default provider (anthropic or openai)
default_provider = anthropic
# Number of lines to show in tool output before truncating (must be positive integer)
tool_output_lines = 10
# Control how pricing information is displayed: disabled, total_only, or detailed
pricing_display = detailed

[model]
# Model configuration
# Must be a positive integer between 1 and 100. When reaching the limit, the model will stop and ask you if you want to continue.
recursion_limit = 30

[inference]
# Temperature for model inference (float between 0.0 and 1.0)
temperature = 0.8
# Maximum tokens for model response (positive integer)
max_tokens = 8192

[anthropic]
# Default model for Anthropic API
# Supported models: claude-3-5-sonnet-20241022, claude-3-7-sonnet-latest
default_model = claude-3-7-sonnet-latest
# Environment variable name for API key (must be uppercase)
api_key_env = ANTHROPIC_API_KEY
# Path to API key file (supports ~ expansion)
api_key_path = ~/.anthropic/api_key
# Beta flags for Anthropic models (comma-separated key:value pairs or 'none')
beta_flags = computer-use-2024-10-22:true

[pricing]
# Pricing information for Claude 3.7 Sonnet (per million tokens - MTok)
claude_input_price = 3.00
claude_output_price = 15.00
claude_cache_creation_price = 3.75
claude_cache_read_price = 0.30

[openai]
# Default model for OpenAI API
# Supported models: o3-mini, gpt-4o, gpt-4.1
default_model = gpt-4.1
# Environment variable name for API key (must be uppercase)
api_key_env = OPENAI_API_KEY
# Path to API key file (supports ~ expansion)
api_key_path = ~/.openai
# Reasoning effort for OpenAI models (low, medium, high)
reasoning_effort="medium",

[google]
# Default model for Google Vertex AI API
# Supported models: gemini-2.5-pro-exp-03-25, gemini-2.5-pro-preview-03-25, gemini-1.5-flash-8b, gemini-2.5-flash-preview-04-17
default_model = gemini-2.5-pro-preview-03-25
# Environment variable name for API key (must be uppercase)
api_key_env = GOOGLE_API_KEY
# Path to API key file (supports ~ expansion)
api_key_path = ~/.secrets/google_api_key.txt

[git]
# Git tracking configuration
enabled = false
# What to do when repository is dirty (stop, stash)
# - stop: Stop processing and return an error message to the user
# - stash: Automatically stash changes before processing (not yet implemented)
dirty_repo_action = stop
# Auto-commit changes (true/false)
auto_commit = true
# Commit message style (short, detailed, bullet_points)
commit_message_style = bullet_points
# Model for commit message generation
model = claude-3-7-sonnet-latest
# Provider for commit message generation (anthropic or openai)
provider = anthropic
# Temperature for commit message generation (float between 0.0 and 1.0)
temperature = 0.7
# Prefix for commit messages
commit_prefix = [VMPilot]
# Author name and email for Git commits
author = VMPilot <vmpilot@vmpilot.org>
# Default project directory (supports ~ expansion). What project are you working on?
# default_project = ~/vmpilot

[pipeline]
# Pipeline configuration for OpenWebUI integration. You probably don't need to change this. Useful when makding changes to VMPilot itself.
# Pipeline name (non-empty string)
name = VMPilot Pipeline
# Pipeline ID (alphanumeric string)
id = vmpilot

[google_search]
enabled = true
api_key_env = GOOGLE_API_KEY
cse_id_env = GOOGLE_CSE_ID
max_results = 10

[web_fetch]
enabled = true
# Maximum number of result lines to from the web fetch to provide to the llm
max_lines = 200

[diffbot]
enabled = true
api_key_env = DIFFBOT_API_KEY

[database]
enabled = true
path = /app/data/vmpilot.db
