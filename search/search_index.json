{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"User guide","text":""},{"location":"#introduction","title":"Introduction","text":"<p>VMpilot is a tool that allows you to collaborate with an LLM primarily for software development, but can be used for any tasks that benefits from an LLM operating in a virtual machine.</p>"},{"location":"#basic-usage","title":"Basic usage","text":"<p>Out of the box, VMPilot has several tools - A shell tool where it can run shell commands - A file editing tool where it can edit files - A file creation tool where it can create files</p> <p>Since it can run a shell command, it can run any command that you can run in a shell. This includes running scripts, installing packages, and running any other command that you can run in a shell.</p> <p>[!CAUTION] Only give the llm access to files and permissions that you are comfortable with. The llm can run any command that you can run in a shell as the logged in user, so it can potentially do anything that you can do in a shell.</p>"},{"location":"#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform.</li> <li>The LLM performs the task and provides the output of any commands it runs.</li> </ol> <p>Example: <pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py\n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py\n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script:\n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several opeartions to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"#choosing-the-provider-and-model","title":"Choosing the provider and model","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider and model you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"#workspaces","title":"Workspaces","text":"<p>Workspaces are very powerful since they allow you to group pipelines and prompt. Examples of workspaces: - My software with OpenAI - My software with Anthropic - Frontend development - Backend development - Personal</p> <p>In your prompt tell the llm - The root directory of your project. This is crucial to understand where to find the files you are working on. - The stack you're using - A description of the project and the hierarchy of the files</p>"},{"location":"#create-a-workspace","title":"Create a workspace","text":"<ul> <li>Click on \"Workspace\"</li> <li>Click on \"+\" to create a new workspace</li> <li>Name it, enter a prompt and edit any other settings</li> <li>Click \"Save\"</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>VMPilot provides a powerful command-line interface that allows you to interact with the tool directly from your terminal.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using the CLI is:</p> <pre><code>cli.sh \"your command here\"\n</code></pre> <p>For example: <pre><code>cli.sh \"Show me the contents of /etc/hosts\"\ncli.sh \"Create a new Python script that prints Hello World\"\ncli.sh  cli.sh  `cat reqeust.sh`\n</code></pre></p> <p>Remember to enclose your command in quotes to ensure that it is passed as a single argument to the CLI. In the last example, we used backticks to execute a command and pass its output as an argument to the CLI.</p>"},{"location":"cli/#command-line-options","title":"Command Line Options","text":"<p>The CLI supports several command line options to customize its behavior:</p> <pre><code>usage: cli.sh [-h] [-t TEMPERATURE] [-p {anthropic,openai}] [-d] request\n\npositional arguments:\n  request               request to the llm\n\noptions:\n  -h, --help           Show this help message and exit\n  -t TEMPERATURE,      Temperature for response generation (default: 0.7)\n  --temperature\n  -p {anthropic,openai},\n  --provider          API provider to use (default: anthropic)\n  -d, --debug         Enable debug mode\n</code></pre>"},{"location":"cli/#temperature","title":"Temperature","text":"<p>The temperature parameter controls the randomness in the response generation. Higher values (e.g., 0.8) make the output more creative but potentially less focused, while lower values (e.g., 0.2) make it more deterministic and focused. As a rule you should not provide a temperature value, since these are set by the API provider. For testing we use a value of 0 so that the output is deterministic.</p> <p>Example: <pre><code>cli.sh -t 0.3 \"Write a Python function to calculate factorial\"\n</code></pre></p>"},{"location":"cli/#provider-selection","title":"Provider Selection","text":"<p>You can choose between different LLM providers: - anthropic (default) - openai</p> <p>Example: <pre><code>cli.sh -p openai \"Explain how to use the ls command\"\n</code></pre></p>"},{"location":"cli/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode to see detailed logging information, which can be helpful for troubleshooting:</p> <pre><code>cli.sh -d \"Show system information\"\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":"<p>Here are some common usage examples:</p> <ol> <li> <p>Basic system operations: <pre><code>cli.sh \"Show me all Python files in the current directory\"\ncli.sh \"Create a new directory called 'test' and add a README file\"\n</code></pre></p> </li> <li> <p>File editing: <pre><code>cli.sh \"Change the word 'error' to 'warning' in log.txt\"\ncli.sh \"Add a new function to myscript.py\"\n</code></pre></p> </li> <li> <p>Using different providers with custom temperature: <pre><code>cli.sh -p openai -t 0.5 \"Optimize this Python script for performance\"\n</code></pre></p> </li> </ol>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI will display error messages when: - The command execution fails - There are permission issues - The LLM provider is not properly configured - Invalid arguments are provided</p> <p>If you encounter errors, try: 1. Using debug mode (-d) to get more information 2. Checking your API provider configuration 3. Verifying you have the necessary permissions for the requested operation</p>"},{"location":"configuration/","title":"Configuration Guide","text":""},{"location":"configuration/#overview","title":"Overview","text":"<p>VMPilot uses a flexible configuration system that supports multiple locations for config files and various settings for LLM providers and model parameters.</p>"},{"location":"configuration/#configuration-file-locations","title":"Configuration File Locations","text":"<p>VMPilot looks for configuration in the following locations (in order): 1. Path specified in VMPILOT_CONFIG environment variable 2. ./config.ini in the project directory 3. config.ini in the current working directory 4. ~/.config/vmpilot/config.ini</p>"},{"location":"configuration/#configuration-file-structure","title":"Configuration File Structure","text":"<p>The configuration file (config.ini) should contain the following sections:</p>"},{"location":"configuration/#general","title":"[general]","text":"<ul> <li>default_provider: The default LLM provider to use (anthropic or openai)</li> <li>tool_output_lines: Number of lines to show in tool output</li> </ul>"},{"location":"configuration/#model","title":"[model]","text":"<ul> <li>recursion_limit: Maximum number of recursive steps the model can take</li> </ul>"},{"location":"configuration/#inference","title":"[inference]","text":"<ul> <li>temperature: Model temperature setting</li> <li>max_tokens: Maximum tokens for model responses</li> </ul>"},{"location":"configuration/#anthropic-openai","title":"[anthropic] / [openai]","text":"<p>Provider-specific settings: - default_model: Default model to use for this provider - api_key_path: Path to API key file - api_key_env: Environment variable name for API key - beta_flags: Optional comma-separated key:value pairs for beta features</p>"},{"location":"configuration/#example-configuration","title":"Example Configuration","text":"<pre><code>[general]\ndefault_provider = anthropic\ntool_output_lines = 15\n\n[model]\nrecursion_limit = 25\n\n[inference]\ntemperature = 0.7\nmax_tokens = 2000\n\n[anthropic]\ndefault_model = claude-2\napi_key_path = ~/.anthropic_key\napi_key_env = ANTHROPIC_API_KEY\n\n[openai]\ndefault_model = gpt-4\napi_key_path = ~/.openai_key\napi_key_env = OPENAI_API_KEY\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<ul> <li>VMPILOT_CONFIG: Optional path to configuration file</li> <li>Provider-specific API key variables (as specified in config.ini)</li> </ul>"},{"location":"dns_ssl_setup/","title":"DNS and SSL Configuration Guide","text":""},{"location":"dns_ssl_setup/#overview","title":"Overview","text":"<p>This guide covers setting up secure access to your OpenWebUI and VMPilot Pipeline services using DNS and SSL certificates. We'll walk through setting up dynamic DNS and configuring Caddy as a reverse proxy with automatic SSL certificate management. This is optional and not only recommended for secure access to your services, it'll make your life easier to not have to deal with browser warnings about insecure connections.</p> <p>[!CAUTION] While I tried to make this guide somewhat comprehensive, check with Claude or GPT for any additional steps or configurations that might be needed for your specific setup.</p>"},{"location":"dns_ssl_setup/#dynamic-dns-setup","title":"Dynamic DNS Setup","text":"<p>If you're running these services from a location without a static IP which is often the case with home servers, you'll need to set up dynamic DNS to ensure your domain/subdomain always points to the correct IP address.</p> <ol> <li>Choose a Dynamic DNS Provider</li> <li> <p>Options include No-IP, DuckDNS, or Cloudflare</p> </li> <li> <p>Register for Dynamic DNS</p> </li> <li>Create an account at your chosen provider</li> <li>Register your desired subdomain</li> <li> <p>Note down your token/credentials</p> </li> <li> <p>Configure Dynamic DNS Client</p> </li> <li> <p>follow the instructions for your chosen provider</p> </li> <li> <p>Start and Enable the Service</p> </li> </ol>"},{"location":"dns_ssl_setup/#caddy-server-setup","title":"Caddy Server Setup","text":"<p>Caddy is a lightweight web server that can handle automatic SSL certificate management and reverse proxying. We'll use Caddy to set up secure access to OpenWebUI and VMPilot Pipeline.</p> <ol> <li> <p>Install Caddy    <pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy\n</code></pre></p> </li> <li> <p>Configure Caddy    Create a Caddyfile:    <pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></p> </li> </ol> <p>Basic configuration for OpenWebUI and Pipeline:    <pre><code>webui.yourdomain.com {\n    reverse_proxy localhost:8080\n}\n\npipeline.yourdomain.com {\n    reverse_proxy localhost:9099\n}\n</code></pre></p> <ol> <li>Start and Enable Caddy    <pre><code>sudo systemctl restart caddy\nsudo systemctl enable caddy\n</code></pre></li> </ol>"},{"location":"dns_ssl_setup/#dns-configuration","title":"DNS Configuration","text":"<ol> <li>Set up A/AAAA Records</li> <li>Point your domain/subdomain to your server's IP</li> <li> <p>If using dynamic DNS, this is handled automatically</p> </li> <li> <p>Verify DNS Propagation    <pre><code>dig webui.yourdomain.com\ndig pipeline.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Check Caddy Status    <pre><code>sudo systemctl status caddy\n</code></pre></p> </li> <li> <p>View Caddy Logs    <pre><code>sudo journalctl -u caddy\n</code></pre></p> </li> <li> <p>Verify SSL Certificates    <pre><code>curl -vI https://webui.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#next-steps","title":"Next Steps","text":"<p>Once DNS and SSL are configured, proceed to Installation Guide for setting up OpenWebUI and VMPilot.</p>"},{"location":"github_issues/","title":"GitHub Issues Plugin","text":"<p>The GitHub Issues plugin enables VMPilot to interact with GitHub issues directly through the GitHub CLI (<code>gh</code>). This plugin provides a seamless way to view, create, and manage GitHub issues without leaving your VMPilot environment.</p>"},{"location":"github_issues/#prerequisites","title":"Prerequisites","text":"<p>Before using the GitHub Issues plugin, ensure you have: - GitHub CLI (<code>gh</code>) installed on your system - Authenticated GitHub CLI access (<code>gh auth login</code>)</p>"},{"location":"github_issues/#features","title":"Features","text":""},{"location":"github_issues/#viewing-issues","title":"Viewing Issues","text":"<p>You can view issues using simple commands like: <pre><code>show me issue 3\n</code></pre> or <pre><code>what's the status of issue #5\n</code></pre></p> <p>The plugin will automatically: 1. Navigate to the project root directory 2. Fetch and display the issue information</p>"},{"location":"github_issues/#creating-issues","title":"Creating Issues","text":"<p>To create a new issue, you can use natural language requests like: <pre><code>create a github issue titled \"Add logging feature\" with label \"enhancement\"\n</code></pre></p> <p>The plugin will: 1. Review the appropriate issue template 2. Gather any required information through conversation 3. Create the issue using the GitHub CLI</p>"},{"location":"github_issues/#common-operations","title":"Common Operations","text":"<p>The plugin supports all basic GitHub issue operations: - Listing all issues - Creating new issues - Viewing specific issues - Closing issues - Reopening issues</p>"},{"location":"github_issues/#best-practices","title":"Best Practices","text":"<ol> <li>Be Specific: When creating issues, provide clear titles and descriptions</li> <li>Use Labels: Include relevant labels to categorize issues properly</li> <li>Template Compliance: Follow any issue templates configured in the repository</li> <li>Confirmation: The plugin will seek confirmation before creating or modifying issues</li> </ol>"},{"location":"github_issues/#technical-details","title":"Technical Details","text":"<p>The plugin operates by: 1. Using the project's root directory as the base for all operations 2. Leveraging the GitHub CLI for all interactions 3. Following repository-specific templates and guidelines</p>"},{"location":"github_issues/#example-usage","title":"Example Usage","text":"<p>Here are some example interactions:</p> <ol> <li> <p>Viewing an issue: <pre><code>show me issue #3\n</code></pre></p> </li> <li> <p>Creating an issue: <pre><code>create an issue for a new feature request:\ntitle: Add dark mode support\nlabel: enhancement\n</code></pre></p> </li> <li> <p>Listing recent issues: <pre><code>show me the open issues\n</code></pre></p> </li> </ol> <p>The plugin will handle all the necessary GitHub CLI commands and provide appropriate feedback for each operation.</p>"},{"location":"installation/","title":"VMPilot Installation Guide","text":"<p>This guide provides comprehensive instructions for setting up VMPilot in your environment.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker container with:</li> <li>ubuntu 22.04 or later</li> <li>python 3.11 or later</li> </ul> <p>Before proceeding with this installation guide, it is recommended that you complete the DNS and SSL Setup to configure secure access to your services.</p> <p>VMPilot in its current form is meant for folks familiar with Docker and Linux. So rather than provide a docker container, we provide the instructions.</p>"},{"location":"installation/#1-set-up-your-virtual-machine","title":"1. Set up your virtual machine","text":"<p>Set up a virtual machine with your standard configuration. You'll be sharing this machine with VMPilot, so set it up in a way that feels comfortable to you.</p> <ul> <li>gvisor is recommended for security. Enable your container runtime to use gvisor.</li> <li>Once you have your virtual machine set up, you can proceed with the installation.</li> </ul>"},{"location":"installation/#2-install-the-apps-on-your-virtual-machine","title":"2. Install the apps on your virtual machine.","text":""},{"location":"installation/#3-installing-openwebui","title":"3. Installing OpenWebUI","text":"<p>OpenWebUI serves as the frontend interface for VMPilot.</p> <p>Follow the instructions on the OpenWebUI GitHub repository</p> <pre><code>pip install open-webui\n</code></pre> <p>and then run the following command:</p> <pre><code>open-webui serve\n</code></pre> <p>You can, of course, follow one of the other methods suggested in the OpenWebUI documentation.</p>"},{"location":"installation/#31-create-a-new-openwebui-user","title":"3.1 Create a new OpenWebUI user","text":"<p>In a browser, navigate to the OpenWebUI interface at your domain or localhost Create a new user on OpenWebUI which, as the first user, will make you the admin user.</p>"},{"location":"installation/#4-install-openwebui-pipelines","title":"4. Install OpenWebUI Pipelines","text":"<p>OpenWebUI Pipelines is required for VMPilot integration.</p> <pre><code>cd ~\ngit clone https://github.com/open-webui/pipelines\n</code></pre> <p>This will clone the repository to your home directory. This is the default location for VMPilot to look for the pipelines.</p>"},{"location":"installation/#41-install-dependencies","title":"4.1 Install dependencies:","text":"<p><pre><code>pip install -r requirements.txt\n</code></pre> You don't need to run the pipelines server, as VMPIlot will run it.</p>"},{"location":"installation/#5-installing-vmpilot","title":"5. Installing VMPilot","text":""},{"location":"installation/#51-server-installation","title":"5.1 Server Installation","text":"<p>Clone the VMPilot repository: <pre><code>cd ~\ngit clone https://github.com/yourusername/vmpilot.git\ncd vmpilot\n</code></pre></p> <p>Install dependencies: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>Set up your credentials. The defaults are: - Anthropic: ~/.anthropic/api_key - OpenAI: ~/.openai</p>"},{"location":"installation/#52-check-the-configuration","title":"5.2 Check the configuration","text":"<p>Look at vmpilot/src/vmpilot/config.ini and make sure the configuration is correct for your setup. Alternatively you can set the environment variable VMPILOT_CONFIG to the path of your configuration file.</p>"},{"location":"installation/#53-start-vmpilot","title":"5.3 Start VMPilot","text":"<pre><code>~/vmpilot/bin/run.sh\n</code></pre>"},{"location":"installation/#32-openwebui-client-configuration","title":"3.2 OpenWebUI Client Configuration","text":"<ol> <li>Access the OpenWebUI interface at your domain or localhost</li> </ol> <p>2 Open OpenWebUI in your browser 2.1 Open OpenWebUI in your browser 2.2 Click on your user name in the bottom left corner 3.3 Click on Admin Panel 3.4 Click on connections</p> <ol> <li>Add VMPilot Connection:</li> <li>URL: http://localhost:9099 and the password</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Enable the pipeline:</p> </li> <li>Go to Pipelines tab</li> <li>Find the above url</li> <li>Enter the keys for the provider you want to use: OpenAI, Anthropic, or both.</li> <li>Click \"Save\"</li> </ol> <p>Note: Because the VMPilot pipeline is a manifold pipeline, you'll see two models in the pipeline list: - VMPilot PipelineAnthropic (Claude) - VMPilot PipelineOpenAI (GPT-4o)</p> <p>Claude is currently the preferred model for VMPilot, since it: - Seems to handle code better. - Is relatively affordable and fast when caching is handled correctly. VMPIlot caches the conversation history, so the model doesn't have to relearn everything every time. - Has been tested more extensively.</p>"},{"location":"installation/#4-verification","title":"4. Verification","text":"<p>To verify your installation:</p> <ol> <li>Open OpenWebUI in your browser. Choose one of the above models and start a conversation.</li> <li>Try a simple command like \"Show me /home\"</li> </ol>"},{"location":"installation/#5-troubleshooting","title":"5 Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Connection refused:</li> <li>Check if VMPilot server is running</li> <li>Verify port configurations</li> <li> <p>Check firewall settings</p> </li> <li> <p>Authentication errors:</p> </li> <li>Verify API key in the UI</li> <li> <p>Check OpenWebUI pipeline configuration</p> </li> <li> <p>Model not found:</p> </li> <li>Go to the connection settings as described above, and save the connection again.</li> <li>Go to the pipeline settings and save the pipeline again.</li> <li>Edit the workplace and make sure the pipeline is selected.</li> </ol>"},{"location":"plugins/","title":"Plugins","text":"<p>VMPilot plugins provide a unique approach to extending LLM functionality through text-based configuration, rather than traditional code-based plugins.</p>"},{"location":"plugins/#how-plugins-work","title":"How Plugins Work","text":"<p>The system injects each plugin's README.md content into the LLM's prompt. Currently, the plugin system looks like this: <pre><code># Available plugins\n\n# Codemap\ndirectory: codemap\nCreates documentation by scanning the code and generating a doc per source file.\n\n# Github\n\ndirectory: github\\_issues\n- To view or list issues, use \"cd $rootDir &amp;&amp; gh issue view $number\" or \"gh issue list\". Always include the \"gh\" command.\n- To create an issue view the README.md file for instructions.\n</code></pre></p>"},{"location":"plugins/#managing-plugins","title":"Managing Plugins","text":"<p>Enabling or disabling plugins is straightforward - simply add or remove their entries from the README.md file.</p>"},{"location":"plugins/#creating-new-plugins","title":"Creating New Plugins","text":"<p>To create a new plugin: 1. Create a directory in the plugins directory 2. Create a README.md file using template.md from the plugins directory as a guide 3. Add your plugin's entry to the main README.md file in the plugins directory 4. Test the plugin functionality with various prompts</p> <p>For examples of existing plugins, see the <code>codemap</code> and <code>github_issues</code> implementations in the plugins directory.</p>"},{"location":"tips/","title":"Tips and Best Practices","text":""},{"location":"tips/#create-a-separate-api-key-for-vmpilot","title":"Create a Separate API Key for VMPilot","text":"<p>When you first start using VMPilot, it's recommended to create a dedicated API key to manage costs effectively. This allows you to: - Set a specific budget for VMPilot usage - Monitor VMPilot-specific API consumption - Keep your other API usage separate</p>"},{"location":"tips/#using-workspaces-in-webui","title":"Using Workspaces in WebUI","text":"<p>Workspaces are powerful organizational tools that allow you to group related pipelines and prompts. Here are some example workspace categories: - My software with OpenAI - My software with Anthropic - Frontend development - Backend development - Personal</p> <p>When setting up a workspace prompt, include: - The root directory of your project (crucial for file operations) - Your technology stack - A brief project description and file structure overview</p>"},{"location":"tips/#creating-a-workspace","title":"Creating a Workspace","text":"<ol> <li>Click on \"Workspace\"</li> <li>Click the \"+\" button to create a new workspace</li> <li>Enter a name and configure the prompt and settings</li> <li>Click \"Save\"</li> </ol>"},{"location":"tips/#managing-chat-length","title":"Managing Chat Length","text":"<p>As conversations grow longer, the LLM's responses may become less focused and effective. When this happens: - Start a new chat session - Reuse or update your original prompt - Copy relevant context from the previous conversation if needed</p>"},{"location":"tips/#working-with-llms-effectively","title":"Working with LLMs Effectively","text":"<p>LLMs can be remarkably capable but also occasionally unpredictable. To get the best results:</p> <ul> <li>Read about prompt engineering. It's a skill that takes time to develop but it's worth it.</li> <li>Don't ask the llm to do too much at once. Break down the task into smaller tasks.</li> <li>Sometimes, you just need to do the task yourself, at least part of it. </li> </ul>"},{"location":"user-guide/","title":"User guide","text":""},{"location":"user-guide/#introduction","title":"Introduction","text":"<p>VMpilot is a tool that allows you to collaborate with an LLM primarily for software development, but can be used for any tasks that benefits from an LLM operating in a virtual machine.</p>"},{"location":"user-guide/#basic-usage","title":"Basic usage","text":"<p>Out of the box, VMPilot has several tools - A shell tool where it can run shell commands - A file editing tool where it can edit files - A file creation tool where it can create files</p> <p>Since it can run a shell command, it can run any command that you can run in a shell. This includes running scripts, installing packages, and running any other command that you can run in a shell.</p> <p>[!CAUTION] Only give the llm access to files and permissions that you are comfortable with. The llm can run any command that you can run in a shell as the logged in user, so it can potentially do anything that you can do in a shell.</p>"},{"location":"user-guide/#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform.</li> <li>The LLM performs the task and provides the output of any commands it runs.</li> <li>Rinse and repeat.</li> </ol> <p>Example: <pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py\n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py\n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script:\n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"user-guide/#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several operation to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"user-guide/#choosing-the-provider-and-model","title":"Choosing the provider and model","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider and model you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"user-guide/#additional-features","title":"Additional Features","text":""},{"location":"user-guide/#plugins","title":"Plugins","text":"<p>VMPilot supports various plugins to extend its functionality. See the Plugins documentation for details about available plugins and how to use them.</p> <p>Some key plugins include: - GitHub Issues - Manage GitHub issues directly from VMPilot - Code Map - Generate code documentation automatically</p>"},{"location":"user-guide/#tips-and-best-practices","title":"Tips and Best Practices","text":"<p>For tips on getting the most out of VMPilot, including workspace management, prompt engineering, and general best practices, see our Tips guide.</p>"}]}