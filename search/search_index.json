{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VMPilot Documentation","text":"<p>Welcome to the VMPilot documentation! VMPilot is an AI-driven system operations assistant with CLI and API interfaces.</p>"},{"location":"#overview","title":"Overview","text":"<p>VMPilot provides:</p> <ul> <li>CLI Interface: Command-line interface for direct system operations</li> <li>Pipeline Mode: OpenWebUI compatible service (port 9099)</li> <li>Extensible Tools: Built-in system operation tools with extensible framework</li> <li>Multiple LLM Support: Integration with various LLM providers</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation Guide</li> <li>Quick Start Tutorial</li> <li>User Guide</li> <li>Architecture Overview</li> </ul>"},{"location":"#features","title":"Features","text":"<ol> <li>LLM Integration</li> <li>Support for multiple providers (Anthropic, OpenAI)</li> <li>Configurable models and parameters</li> <li> <p>Streaming response capability</p> </li> <li> <p>Tool System</p> </li> <li>Extensible tool framework</li> <li>Built-in file and system operations</li> <li> <p>Error handling and result management</p> </li> <li> <p>Pipeline Architecture</p> </li> <li>Message processing pipeline</li> <li>Asynchronous operation support</li> <li>State management and checkpointing</li> </ol>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>Check the User Guide for detailed usage instructions</li> <li>Visit the Development Guide to contribute</li> <li>Review the API Reference for integration details</li> </ul>"},{"location":"getting-started/installation/","title":"VMPilot Installation Guide","text":"<p>This guide provides comprehensive instructions for setting up VMPilot in your environment.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker container with:</li> <li>ubuntu 22.04 or later</li> <li>python 3.11 or later</li> </ul> <p>Before proceeding with this installation guide, it is recommended that you complete the DNS and SSL Setup to configure secure access to your services.</p> <p>VMPilot in its current form is meant for folks familiar with Docker and Linux. So rather than provide a docker container, we provide the instructions.</p>"},{"location":"getting-started/installation/#1-set-up-your-virtual-machine","title":"1. Set up your virtual machine","text":"<p>Set up a virtual machine with your standard configuration. You'll be sharing this machine with VMPilot, so set it up in a way that feels comfortable to you.</p> <ul> <li>(gvisor)[https://gvisor.dev/docs/user_guide/install/] is recommended for Security. Enable your container runtime to use gvisor.</li> <li>Once you have your virtual machine set up, you can proceed with the installation.</li> </ul>"},{"location":"getting-started/installation/#2-install-the-apps-on-your-virtual-machine","title":"2. Install the apps on your virtual machine.","text":""},{"location":"getting-started/installation/#3-installing-openwebui","title":"3. Installing OpenWebUI","text":"<p>OpenWebUI serves as the frontend interface for VMPilot.</p> <p>Follow the instructions on the OpenWebUI GitHub repository</p> <pre><code>pip install open-webui\n</code></pre> <p>and then run the following command:</p> <pre><code>open-webui serve\n</code></pre> <p>You can, of course, follow one of the other methods suggested in the OpenWebUI documentation.</p>"},{"location":"getting-started/installation/#31-create-a-new-user","title":"3.1 Create a new user","text":"<p>In a browser, navigate to the OpenWebUI interface at your domain or localhost Create a new user on OpenWebUI which, as the first user, will make you the admin user.</p>"},{"location":"getting-started/installation/#4-install-openwebui-pipelines","title":"4. Install OpenWebUI Pipelines","text":"<p>OpenWebUI Pipelines is required for VMPilot integration.</p> <pre><code>cd ~\ngit clone https://github.com/open-webui/pipelines\n</code></pre> <p>This will clone the repository to your home directory. This is the default location for VMPilot to look for the pipelines.</p>"},{"location":"getting-started/installation/#41-install-dependencies","title":"4.1 Install dependencies:","text":"<p><pre><code>pip install -r requirements.txt\n</code></pre> You don't need to run the pipelines server, as VMPIlot will run it.</p>"},{"location":"getting-started/installation/#5-installing-vmpilot","title":"5. Installing VMPilot","text":""},{"location":"getting-started/installation/#51-server-installation","title":"5.1 Server Installation","text":"<p>Clone the VMPilot repository: <pre><code>cd ~\ngit clone https://github.com/yourusername/vmpilot.git\ncd vmpilot\n</code></pre></p> <p>Install dependencies: <pre><code>pip install -r requirements.txt\n</code></pre></p> <p>Set up your credentials. The defaults are: - Anthropic: ~/.anthropic/api_key - OpenAI: ~/.openai</p>"},{"location":"getting-started/installation/#52-check-the-configuration","title":"5.2 Check the configuration","text":"<p>Look at vmpilot/src/vmpilot/config.ini and make sure the configuration is correct for your setup. Alternatively you can set the environment variable VMPILOT_CONFIG to the path of your configuration file.</p>"},{"location":"getting-started/installation/#53-start-vmpilot","title":"5.3 Start VMPilot","text":"<pre><code>~/vmpilot/bin/run.sh\n</code></pre>"},{"location":"getting-started/installation/#32-openwebui-client-configuration","title":"3.2 OpenWebUI Client Configuration","text":"<ol> <li>Access the OpenWebUI interface at your domain or localhost</li> </ol> <p>2 Open OpenWebUI in your browser 2.1 Open OpenWebUI in your browser 2.2 Click on your user name in the bottom left corner 3.3 Click on Admin Panel 3.4 Click on connections</p> <ol> <li>Add VMPilot Connection:</li> <li>URL: http://localhost:9099 and the password</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Enable the pipeline:</p> </li> <li>Go to Pipelines tab</li> <li>Find the above url</li> <li>Enter the keys for the provider you want to use: OpenAI, Anthropic, or both.</li> <li>Click \"Save\"</li> </ol> <p>Note: Because the VMPilot pipeline is a manifold pipeline, you'll see two models in the pipeline list: - VMPilot PipelineAnthropic (Claude) - VMPilot PipelineOpenAI (GPT-4o)</p> <p>Claude is currently the preferred model for VMPilot, since it has been tested more extensively.</p>"},{"location":"getting-started/installation/#4-verification","title":"4. Verification","text":"<p>To verify your installation:</p> <ol> <li>Open OpenWebUI in your browser. Choose one of the above models and start a conversation.</li> <li>Try a simple command like \"Show me /home\"</li> </ol>"},{"location":"getting-started/installation/#5-troubleshooting","title":"5 Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Connection refused:</li> <li>Check if VMPilot server is running</li> <li>Verify port configurations</li> <li> <p>Check firewall settings</p> </li> <li> <p>Authentication errors:</p> </li> <li>Verify API key in the UI</li> <li> <p>Check OpenWebUI pipeline configuration</p> </li> <li> <p>Model not found:</p> </li> <li>Go to the connection settings as described above, and save the connection again.</li> <li>Go to the pipeline settings and save the pipeline again.</li> <li>Edit the workplace and make sure the pipeline is selected.</li> </ol>"},{"location":"user-guide/","title":"User guide","text":""},{"location":"user-guide/#introduction","title":"Introduction","text":"<p>VMpilot is a tool that allows you to collaborate with an LLM primarily for software development, but can be used for any tasks that benefits from an LLM operating in a virtual machine.</p>"},{"location":"user-guide/#basic-usage","title":"Basic usage","text":"<p>Out of the box, VMPilot has several tools - A shell tool where it can run shell commands - A file editing tool where it can edit files - A file creation tool where it can create files</p> <p>Since it can run a shell command, it can run any command that you can run in a shell. This includes running scripts, installing packages, and running any other command that you can run in a shell.</p> <p>[!CAUTION] Only give the llm access to files and permissions that you are comfortable with. The llm can run any command that you can run in a shell as the logged in user, so it can potentially do anything that you can do in a shell.</p>"},{"location":"user-guide/#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform. </li> <li>The LLM performs the task and provides the output of any commands it runs.</li> </ol> <p>Example: <pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py  \n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py  \n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script: \n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"user-guide/#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several opeartions to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"user-guide/#choosing-the-provider-and-model","title":"Choosing the provider and model","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider and model you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"user-guide/#workspaces","title":"Workspaces","text":"<p>Workspaces are very powerful since they allow you to group pipelines and prompt. Examples of workspaces: - My software with OpenAI - My software with Anthropic - Frontend development - Backend development - Personal</p> <p>In your prompt tell the llm - The root directory of your project. This is crucial to understand where to find the files you are working on. - The stack you're using - A description of the project and the hierarchy of the files</p>"},{"location":"user-guide/#create-a-workspace","title":"Create a workspace","text":"<ul> <li>Click on \"Workspace\"</li> <li>Click on \"+\" to create a new workspace</li> <li>Name it, enter a prompt and edit any other settings</li> <li>Click \"Save\"</li> </ul>"},{"location":"user-guide/cli/","title":"Command Line Interface (CLI)","text":"<p>VMPilot provides a powerful command-line interface that allows you to interact with the tool directly from your terminal. </p>"},{"location":"user-guide/cli/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using the CLI is:</p> <pre><code>cli.sh \"your command here\"\n</code></pre> <p>For example: <pre><code>cli.sh \"Show me the contents of /etc/hosts\"\ncli.sh \"Create a new Python script that prints Hello World\"\ncli.sh  cli.sh  `cat reqeust.sh`\n</code></pre></p> <p>Remember to enclose your command in quotes to ensure that it is passed as a single argument to the CLI.  In the last example, we used backticks to execute a command and pass its output as an argument to the CLI.</p>"},{"location":"user-guide/cli/#command-line-options","title":"Command Line Options","text":"<p>The CLI supports several command line options to customize its behavior:</p> <pre><code>usage: cli.sh [-h] [-t TEMPERATURE] [-p {anthropic,openai}] [-d] request\n\npositional arguments:\n  request               request to the llm\n\noptions:\n  -h, --help           Show this help message and exit\n  -t TEMPERATURE,      Temperature for response generation (default: 0.7)\n  --temperature\n  -p {anthropic,openai},\n  --provider          API provider to use (default: anthropic)\n  -d, --debug         Enable debug mode\n</code></pre>"},{"location":"user-guide/cli/#temperature","title":"Temperature","text":"<p>The temperature parameter controls the randomness in the response generation. Higher values (e.g., 0.8) make the output more creative but potentially less focused, while lower values (e.g., 0.2) make it more deterministic and focused. As a rule you should not provide a temperature value, since these are set by the API provider. For testing we use a value of 0 so that the output is deterministic.</p> <p>Example: <pre><code>cli.sh -t 0.3 \"Write a Python function to calculate factorial\"\n</code></pre></p>"},{"location":"user-guide/cli/#provider-selection","title":"Provider Selection","text":"<p>You can choose between different LLM providers: - anthropic (default) - openai</p> <p>Example: <pre><code>cli.sh -p openai \"Explain how to use the ls command\"\n</code></pre></p>"},{"location":"user-guide/cli/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode to see detailed logging information, which can be helpful for troubleshooting:</p> <pre><code>cli.sh -d \"Show system information\"\n</code></pre>"},{"location":"user-guide/cli/#examples","title":"Examples","text":"<p>Here are some common usage examples:</p> <ol> <li> <p>Basic system operations: <pre><code>cli.sh \"Show me all Python files in the current directory\"\ncli.sh \"Create a new directory called 'test' and add a README file\"\n</code></pre></p> </li> <li> <p>File editing: <pre><code>cli.sh \"Change the word 'error' to 'warning' in log.txt\"\ncli.sh \"Add a new function to myscript.py\"\n</code></pre></p> </li> <li> <p>Using different providers with custom temperature: <pre><code>cli.sh -p openai -t 0.5 \"Optimize this Python script for performance\"\n</code></pre></p> </li> </ol>"},{"location":"user-guide/cli/#error-handling","title":"Error Handling","text":"<p>The CLI will display error messages when: - The command execution fails - There are permission issues - The LLM provider is not properly configured - Invalid arguments are provided</p> <p>If you encounter errors, try: 1. Using debug mode (-d) to get more information 2. Checking your API provider configuration 3. Verifying you have the necessary permissions for the requested operation</p>"}]}