{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to VMPilot","text":"<ul> <li>Welcome to VMPilot<ul> <li>Key Features</li> <li>Quick Start Guide</li> <li>Core Documentation<ul> <li>Essential Guides</li> <li>Tools and Extensions</li> </ul> </li> </ul> </li> </ul> <p>VMPilot is a chat-based AI development agent that operates directly in your virtual machine environment. It combines natural language understanding with the ability to perform complex development tasks - reading and modifying code, managing GitHub issues, and executing system commands. Powered by OpenWebUI's rich chat interface, it provides an intuitive way to interact with your development environment through workspaces, advanced chat features, and support for multiple AI models.</p> <p>[!CAUTION] Only run this if you have enough knowledge about the security implications of running arbitrary commands in your virtual machine. Never run this directly on your personal machine. You are letting the AI/LLM pilot run commands in your machine and it can be dangerous.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>\ud83d\udd39 Full System Access - Operates directly within your virtual machine environment - Executes and chains system commands intelligently - Manages files, services, and system operations - Understands your entire development environment</p> <p>\ud83d\udd39 End-to-End Development Support - Works directly in your development environment - Writes and modifies code based on your requirements - Reads and analyzes test outputs to guide fixes - Integrates with GitHub for issue management - Understands project context and maintains consistency</p> <p>\ud83d\udd39 Extensible Plugin Architecture - Built-in GitHub integration for issues and code management - Plugin system ready for custom workflow extensions - Future plugins planned for documentation and testing</p> <p>\ud83d\udd39 Multiple Interfaces &amp; OpenWebUI Integration - Powerful CLI for terminal-based workflows - Rich web interface with advanced features:   - Multi-modal conversation view with code highlighting   - Real-time streaming responses   - Conversation history and context management   - Workspace organization and customization   - Support for multiple LLM providers</p>"},{"location":"#quick-start-guide","title":"Quick Start Guide","text":"<p>Get up and running with VMPilot in minutes:</p> <ol> <li>Installation - Set up VMPilot on your system</li> <li>Configuration - Configure your environment</li> <li>User Guide - Learn the basics of VMPilot</li> </ol>"},{"location":"#core-documentation","title":"Core Documentation","text":""},{"location":"#essential-guides","title":"Essential Guides","text":"<ul> <li>Prompting Guide - Master effective prompt writing for VMPilot</li> <li>Tips and Best Practices - Learn proven techniques and best practices</li> <li>CLI Reference - Complete command-line interface documentation</li> </ul>"},{"location":"#tools-and-extensions","title":"Tools and Extensions","text":"<ul> <li>Plugins - Extend VMPilot's capabilities with plugins</li> <li>GitHub Issues - Streamline GitHub issue management</li> <li>DNS and SSL Setup - Secure your VMPilot deployment</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>VMPilot provides a powerful command-line interface that allows you to interact with the tool directly from your terminal.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using the CLI is:</p> Bash<pre><code>cli.sh \"your command here\"\n</code></pre> <p>For example: Bash<pre><code>cli.sh \"Show me the contents of /etc/hosts\"\ncli.sh \"Create a new Python script that prints Hello World\"\ncli.sh  `cat request.sh`\n</code></pre></p> <p>Remember to enclose your command in quotes to ensure that it is passed as a single argument to the CLI. In the last example, we used backticks to execute a command and pass its output as an argument to the CLI.</p>"},{"location":"cli/#command-line-options","title":"Command Line Options","text":"<p>The CLI supports several command line options to customize its behavior:</p> Text Only<pre><code>usage: cli.py [-h] [-t TEMPERATURE] [-f FILE] [-p {anthropic,openai}] [-d] [-c [CHAT]] [command]\n\npositional arguments:\n  command               Command to execute (not required if using -f/--file)\n\noptions:\n  -h, --help           Show this help message and exit\n  -t TEMPERATURE,      Temperature for response generation (default: 0.8)\n  --temperature\n  -f FILE, --file FILE Input file with commands (one per line)\n  -p {anthropic,openai},\n  --provider          API provider to use (default: anthropic)\n  -d, --debug         Enable debug mode\n  -c [CHAT], --chat [CHAT]\n                      Enable chat mode to maintain conversation context. Optional: provide a specific chat ID.\n</code></pre>"},{"location":"cli/#temperature","title":"Temperature","text":"<p>The temperature parameter controls the randomness in the response generation. Higher values (e.g., 0.8) make the output more creative but potentially less focused, while lower values (e.g., 0.2) make it more deterministic and focused. As a rule you should not provide a temperature value, since these are set by the API provider. For testing we use a value of 0 so that the output is deterministic.</p> <p>Example: Bash<pre><code>cli.sh -t 0.3 \"Write a Python function to calculate factorial\"\n</code></pre></p>"},{"location":"cli/#chat-mode","title":"Chat Mode","text":"<p>Chat mode maintains conversation context across multiple commands, allowing for follow-up questions and references to previous interactions.</p> <p>Examples: Bash<pre><code># Start a chat session\ncli.sh -c \"List all Python files\"\n\n# Continue the same chat session\ncli.sh -c \"Explain what these files do\"\n\n# Specify a custom chat ID\ncli.sh -c my_session_123 \"Show system information\"\n\n# Combine with file input for batch processing with context\ncli.sh -f commands.txt -c\n</code></pre></p>"},{"location":"cli/#file-input-mode","title":"File Input Mode","text":"<p>The file input mode allows you to provide a file containing multiple commands, with each command on a separate line. VMPilot will: 1. It creates a unique chat ID for the session, unless you specify one 2. Processes each line in the file as a separate command while maintaining conversation context 3. This simulates a continuous conversation as if you were interacting with VMPilot in chat mode It's similar to chat mode, but with commands read from a file, making it easier to process multiple tasks in sequence.</p> <p>Example: Bash<pre><code>cli.sh -f commands.txt\n</code></pre></p> <p>Where <code>commands.txt</code> might contain: Text Only<pre><code>List all files in the current directory\nShow me the content of the largest file\nExplain what it does\n</code></pre></p>"},{"location":"cli/#provider-selection","title":"Provider Selection","text":"<p>You can choose between different LLM providers: - anthropic (default) - openai</p> <p>Example: Bash<pre><code>cli.sh -p openai \"Explain how to use the ls command\"\n</code></pre></p>"},{"location":"cli/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode to see detailed logging information, which can be helpful for troubleshooting:</p> Bash<pre><code>cli.sh -d \"Show system information\"\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":"<p>Here are some common usage examples:</p> <ol> <li> <p>Basic system operations: Bash<pre><code>cli.sh \"Show me all Python files in the current directory\"\ncli.sh \"Create a new directory called 'test' and add a README file\"\n</code></pre></p> </li> <li> <p>File editing: Bash<pre><code>cli.sh \"Change the word 'error' to 'warning' in log.txt\"\ncli.sh \"Add a new function to myscript.py\"\n</code></pre></p> </li> <li> <p>Using different providers with custom temperature: Bash<pre><code>cli.sh -p openai -t 0.5 \"Optimize this Python script for performance\"\n</code></pre></p> </li> <li> <p>Chat sessions for complex tasks: Bash<pre><code># First command in a chat session\ncli.sh -c \"Find all log files with errors\"\n\n# Follow-up in the same session\ncli.sh -c \"Summarize the most common errors\"\n\n# Another follow-up\ncli.sh -c \"Create a script to fix these errors\"\n</code></pre></p> </li> <li> <p>Batch processing with file input: Bash<pre><code># Create a file with multiple commands\necho \"List all services running\" &gt; tasks.txt\necho \"Show disk usage\" &gt;&gt; tasks.txt\necho \"Find large log files\" &gt;&gt; tasks.txt\n\n# Process all commands in sequence with context\ncli.sh -f tasks.txt -c\n</code></pre></p> </li> </ol>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI will display error messages when: - The command execution fails - There are permission issues - The LLM provider is not properly configured - Invalid arguments are provided</p> <p>If you encounter errors, try: 1. Using debug mode (-d) to get more information 2. Checking your API provider configuration 3. Verifying you have the necessary permissions for the requested operation 4. For file input mode, ensure each command is on a separate line</p>"},{"location":"configuration/","title":"VMPilot Configuration Guide","text":""},{"location":"configuration/#overview","title":"Overview","text":"<p>VMPilot features a flexible configuration system that allows you to customize your environment, LLM providers, and model parameters. This guide explains all available configuration options and how to set them up.</p>"},{"location":"configuration/#applying-configuration-changes","title":"Applying Configuration Changes","text":"<p>After modifying the <code>config.ini</code> file, you must restart the VMPilot server for the changes to take effect.</p>"},{"location":"configuration/#docker-install-configuration-file-location","title":"Docker Install: Configuration File Location","text":"<p>For Docker installations, assuming you are using the default volume setup, the configuration file is located at <code>/var/lib/docker/volumes/vmpilot_config/_data/config.ini</code></p> <p>To apply changes, restart the VMPilot container: Bash<pre><code>docker exec vmpilot supervisorctl restart vmpilot\n</code></pre></p>"},{"location":"configuration/#manual-install-configuration-file-priority","title":"Manual Install: Configuration File Priority","text":"<p>VMPilot searches for configuration files in the following order:</p> <ol> <li>Custom path specified in <code>VMPILOT_CONFIG</code> environment variable</li> <li><code>./config.ini</code> in the project directory</li> <li><code>config.ini</code> in the current working directory</li> <li><code>~/.config/vmpilot/config.ini</code></li> </ol> <p>The first configuration file found will be used.</p> <p>To apply changes, restart the VMPilot server: Bash<pre><code>$MVPILOT_HOME/bin/run.sh\n</code></pre></p>"},{"location":"configuration/#configuration-sections","title":"Configuration Sections","text":"<p>The <code>config.ini</code> file is organized into the following sections:</p>"},{"location":"configuration/#general-settings-general","title":"General Settings [general]","text":"Setting Description Default default_provider Primary LLM provider (anthropic/openai) anthropic tool_output_lines Number of lines shown in tool output 15"},{"location":"configuration/#model-settings-model","title":"Model Settings [model]","text":"Setting Description Default recursion_limit Maximum recursive steps allowed 25"},{"location":"configuration/#inference-settings-inference","title":"Inference Settings [inference]","text":"Setting Description Default temperature Model creativity (0.0-1.0) 0.7 max_tokens Maximum response length 2000"},{"location":"configuration/#provider-settings-anthropic-openai","title":"Provider Settings [anthropic] / [openai]","text":"Setting Description Example default_model Default model name claude-3.5 Sonnet api_key_path Path to API key file ~/.anthropic_key api_key_env API key environment variable ANTHROPIC_API_KEY beta_flags Optional beta features (key:value pairs) feature1:on,feature2:off"},{"location":"configuration/#example-configuration","title":"Example Configuration","text":"INI<pre><code>[general]\ndefault_provider = anthropic\ntool_output_lines = 15\n\n[model]\nrecursion_limit = 25\n\n[inference]\ntemperature = 0.7\nmax_tokens = 2000\n\n[anthropic]\ndefault_model = claude-2\napi_key_path = ~/.anthropic_key\napi_key_env = ANTHROPIC_API_KEY\n\n[openai]\ndefault_model = gpt-4\napi_key_path = ~/.openai_key\napi_key_env = OPENAI_API_KEY\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<ul> <li>VMPILOT_CONFIG: Optional path to configuration file</li> <li>Provider-specific API key variables (as specified in config.ini)</li> </ul>"},{"location":"dns_ssl_setup/","title":"DNS and SSL Configuration Guide","text":""},{"location":"dns_ssl_setup/#overview","title":"Overview","text":"<p>This guide covers setting up secure access to your OpenWebUI and VMPilot Pipeline services using DNS and SSL certificates. We'll walk through setting up dynamic DNS and configuring Caddy as a reverse proxy with automatic SSL certificate management. This is optional and not only recommended for secure access to your services, it'll make your life easier to not have to deal with browser warnings about insecure connections.</p> <p>[!CAUTION] While I tried to make this guide somewhat comprehensive, check with Claude or GPT for any additional steps or configurations that might be needed for your specific setup.</p>"},{"location":"dns_ssl_setup/#dynamic-dns-setup","title":"Dynamic DNS Setup","text":"<p>If you're running these services from a location without a static IP which is often the case with home servers, you'll need to set up dynamic DNS to ensure your domain/subdomain always points to the correct IP address.</p> <ol> <li>Choose a Dynamic DNS Provider</li> <li> <p>Options include No-IP, DuckDNS, or Cloudflare</p> </li> <li> <p>Register for Dynamic DNS</p> </li> <li>Create an account at your chosen provider</li> <li>Register your desired subdomain</li> <li> <p>Note down your token/credentials</p> </li> <li> <p>Configure Dynamic DNS Client</p> </li> <li> <p>follow the instructions for your chosen provider</p> </li> <li> <p>Start and Enable the Service</p> </li> </ol>"},{"location":"dns_ssl_setup/#caddy-server-setup","title":"Caddy Server Setup","text":"<p>Caddy is a lightweight web server that can handle automatic SSL certificate management and reverse proxying. We'll use Caddy to set up secure access to OpenWebUI and VMPilot Pipeline.</p> <ol> <li> <p>Install Caddy    Bash<pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy\n</code></pre></p> </li> <li> <p>Configure Caddy    Create a Caddyfile:    Bash<pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></p> </li> </ol> <p>Basic configuration for OpenWebUI and Pipeline:    Text Only<pre><code>webui.yourdomain.com {\n    reverse_proxy localhost:8080\n}\n\npipeline.yourdomain.com {\n    reverse_proxy localhost:9099\n}\n</code></pre></p> <ol> <li>Start and Enable Caddy    Bash<pre><code>sudo systemctl restart caddy\nsudo systemctl enable caddy\n</code></pre></li> </ol>"},{"location":"dns_ssl_setup/#dns-configuration","title":"DNS Configuration","text":"<ol> <li>Set up A/AAAA Records</li> <li>Point your domain/subdomain to your server's IP</li> <li> <p>If using dynamic DNS, this is handled automatically</p> </li> <li> <p>Verify DNS Propagation    Bash<pre><code>dig webui.yourdomain.com\ndig pipeline.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Check Caddy Status    Bash<pre><code>sudo systemctl status caddy\n</code></pre></p> </li> <li> <p>View Caddy Logs    Bash<pre><code>sudo journalctl -u caddy\n</code></pre></p> </li> <li> <p>Verify SSL Certificates    Bash<pre><code>curl -vI https://webui.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#next-steps","title":"Next Steps","text":"<p>Once DNS and SSL are configured, proceed to Installation Guide for setting up OpenWebUI and VMPilot.</p>"},{"location":"installation/","title":"VMPilot Installation Guide","text":"<ul> <li>VMPilot Installation Guide</li> <li>Prerequisites</li> <li>1. Install VMPilot<ul> <li>1.1 Docker Installation</li> <li>1.2 Manual Installation<ul> <li>1.2.1 Virtual Machine Setup</li> <li>1.2.2 Install OpenWebUI Pipelines</li> <li>1.2.3 Install dependencies:</li> <li>1.2.4 Installing VMPilot</li> <li>1.2.5 Server Installation</li> <li>1.2.6 Configuration Setup</li> <li>1.2.7 Start VMPilot</li> </ul> </li> <li>2. OpenWebUI Setup<ul> <li>2.1 OpenWebUI Installation</li> <li>2.2 Create a new OpenWebUI user</li> <li>3 OpenWebUI Configuration</li> <li>4. Verification</li> <li>4. Troubleshooting</li> </ul> </li> </ul> </li> </ul> <p>This guide provides step-by-step instructions for setting up VMPilot in your environment.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have: - Docker container running Ubuntu 22.04 or later - Python 3.11 or later - Basic familiarity with Docker and Linux</p> <p>For secure access setup, we recommend you complete the DNS and SSL Setup before proceeding.</p>"},{"location":"installation/#1-install-vmpilot","title":"1. Install VMPilot","text":""},{"location":"installation/#11-docker-installation","title":"1.1 Docker Installation","text":"<p>VMPilot is available as a Docker container from GitHub Container Registry (ghcr.io). Note that this is an Ubuntu based container. If you'd like to use a different distribution, you need to install VMPilot manually. Follow these steps to install and run VMPilot in a Docker container:</p> <ol> <li> <p>Pull the latest VMPilot image: Bash<pre><code>docker pull ghcr.io/drorm/vmpilot:latest\n</code></pre></p> </li> <li> <p>Run the container (Docker will automatically create the required volumes): Bash<pre><code>docker run -d \\\n  --name vmpilot \\\n  --security-opt no-new-privileges=true \\\n  -p 9099:9099 \\\n  -v \"vmpilot_config:/app/config:ro\" \\\n  -v \"vmpilot_data:/app/data\" \\\n  -e VMPILOT_CONFIG=/app/config/config.ini \\\n  -e PYTHONUNBUFFERED=1 \\\n  -e LOG_LEVEL=INFO \\\n  --restart unless-stopped \\\n  ghcr.io/drorm/vmpilot:latest\n</code></pre></p> </li> </ol> <p>This will: - Start VMPilot in pipeline mode on port 9099 - Mount persistent volumes for configuration and data - Apply security settings - Configure automatic restart</p> <ol> <li>Verify the container is running: Bash<pre><code>docker ps | grep vmpilot\n</code></pre></li> </ol> <p>The Docker container works out of the box without any initial configuration changes. You only need to: 1. Set up the OpenWebUI connection and pipeline as described in Section 3 2. Add your API keys (OpenAI and/or Anthropic) in the OpenWebUI pipeline configuration</p> <p>Optional Configuration: - If you want to customize VMPilot's behavior, you can modify the config file at <code>/var/lib/docker/volumes/vmpilot_config/_data/config.ini</code> - When using the VMPilot CLI interface (not open-webui), you will need to set up a password as described in the Security section</p> <p>Note: Most users won't need to modify config.ini unless they have specific requirements for customization.</p>"},{"location":"installation/#12-manual-installation","title":"1.2 Manual Installation","text":""},{"location":"installation/#121-virtual-machine-setup","title":"1.2.1 Virtual Machine Setup","text":"<ul> <li>Set up your Docker virtual machine according to your requirements</li> <li>For enhanced security, install gvisor and configure your container runtime to use it</li> </ul>"},{"location":"installation/#122-install-openwebui-pipelines","title":"1.2.2 Install OpenWebUI Pipelines","text":"<p>OpenWebUI Pipelines is required for VMPilot integration.</p> Bash<pre><code>cd ~\ngit clone https://github.com/open-webui/pipelines\n</code></pre> <p>This will clone the repository to your home directory. This is the default location for VMPilot to look for the pipelines.</p>"},{"location":"installation/#123-install-dependencies","title":"1.2.3 Install dependencies:","text":"<p>Bash<pre><code>pip install -r requirements.txt\n</code></pre> You don't need to run the pipelines server, as VMPIlot will run it.</p>"},{"location":"installation/#124-installing-vmpilot","title":"1.2.4 Installing VMPilot","text":""},{"location":"installation/#125-server-installation","title":"1.2.5 Server Installation","text":"<p>Clone the VMPilot repository: Bash<pre><code>cd ~\ngit clone https://github.com/drorm/vmpilot.git\ncd vmpilot\n</code></pre></p> <p>Install dependencies: Bash<pre><code>pip install -r requirements.txt\n</code></pre></p> <p>Set up your credentials. The defaults are: - Anthropic: ~/.anthropic/api_key - OpenAI: ~/.openai</p>"},{"location":"installation/#126-configuration-setup","title":"1.2.6 Configuration Setup","text":"<p>For CLI usage: 1. Set up your password (required for CLI mode) 2. Review vmpilot/src/vmpilot/config.ini - the defaults will work for most setups 3. Optionally, you can set the environment variable VMPILOT_CONFIG to use a custom configuration file</p>"},{"location":"installation/#127-start-vmpilot","title":"1.2.7 Start VMPilot","text":"Bash<pre><code>~/vmpilot/bin/run.sh\n</code></pre>"},{"location":"installation/#2-openwebui-setup","title":"2. OpenWebUI Setup","text":""},{"location":"installation/#21-openwebui-installation","title":"2.1 OpenWebUI Installation","text":"<p>OpenWebUI serves as the frontend interface for VMPilot.</p> <p>Follow the instructions on the OpenWebUI GitHub repository</p> Bash<pre><code>pip install open-webui\n</code></pre> <p>and then run the following command:</p> Bash<pre><code>open-webui serve\n</code></pre> <p>You can, of course, follow one of the other methods suggested in the OpenWebUI documentation, such as using Docker.</p>"},{"location":"installation/#22-create-a-new-openwebui-user","title":"2.2 Create a new OpenWebUI user","text":"<p>In a browser, navigate to the OpenWebUI interface at your domain or localhost Create a new user on OpenWebUI which, as the first user, will make you the admin user.</p>"},{"location":"installation/#3-openwebui-configuration","title":"3 OpenWebUI Configuration","text":"<ol> <li>Access the OpenWebUI interface at your domain or localhost</li> <li>Open OpenWebUI in your browser</li> <li>Click on your user name in the bottom left corner</li> <li>Click on Admin Panel</li> <li>Click on connections</li> <li>Add VMPilot Connection:</li> <li>URL: http://localhost:9099 and the password</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Enable the pipeline:</p> </li> <li>Go to Pipelines tab</li> <li>Find the above url</li> <li>Enter the keys for the provider you want to use: OpenAI, Anthropic, or both.</li> <li>Click \"Save\"</li> </ol> <p>Note: Because the VMPilot pipeline is a manifold pipeline, you'll see two models in the pipeline list:</p> <ul> <li>VMPilot PipelineAnthropic (Claude)</li> <li>VMPilot PipelineOpenAI (GPT-4o)</li> </ul> <p>Claude is currently the preferred model for VMPilot, since it: - Seems to handle code better. - Is relatively affordable and fast when caching is handled correctly. VMPIlot caches the conversation history, so the model doesn't have to relearn everything every time. - Has been tested more extensively.</p>"},{"location":"installation/#4-verification","title":"4. Verification","text":"<p>To verify your installation:</p> <ol> <li>Open OpenWebUI in your browser. Choose one of the above models and start a conversation.</li> <li>Try a simple command like \"Show me /home\"</li> </ol>"},{"location":"installation/#4-troubleshooting","title":"4. Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li> <p>Connection refused:</p> <ul> <li>Check if VMPilot server is running</li> <li>Verify port configurations</li> <li>Check firewall settings</li> </ul> </li> <li> <p>Authentication errors:</p> <ul> <li>Verify API key in the UI</li> <li>Check OpenWebUI pipeline configuration</li> </ul> </li> <li> <p>Model not found:</p> <ul> <li>Go to the connection settings as described above, and save the connection again.</li> <li>Go to the pipeline settings and save the pipeline again.</li> <li>When using a workspace, edit the workspace and make sure the pipeline is selected.</li> </ul> </li> </ol>"},{"location":"prompting/","title":"VMPilot Context Management System","text":""},{"location":"prompting/#understanding-vmpilots-approach","title":"Understanding VMPilot's Approach","text":"<p>Whenever you start a conversation with an LLM, it has no context or memory of previous interactions. You need to provide context and direction. VMPilot uses a multi-level prompting system to ensure the LLM has the necessary context to assist effectively.</p>"},{"location":"prompting/#context-layers","title":"Context Layers","text":""},{"location":"prompting/#1-project-context-workspace-level","title":"1. Project Context (Workspace Level)","text":"<p>Managed through OpenWebUI workspaces provide a high-level overview: YAML<pre><code>Essential Components:\n- Project Root Directory: /path/to/project in the vm.\n- Technology Stack: [languages, frameworks, tools]\n- Project Structure: Directory layout and key files\n- Development Guidelines: Coding standards, workflows\n</code></pre></p>"},{"location":"prompting/#2-task-context-github-integration","title":"2. Task Context (GitHub Integration)","text":"<p>Leveraged through the GitHub Issues plugin: YAML<pre><code>Available Information:\n- Issue Details: Requirements, objectives\n- Discussion History: Comments, feedback\n- Project Metadata: Labels, milestones\n- Related Issues: Dependencies, blockers\n</code></pre></p>"},{"location":"prompting/#workspace-management","title":"Workspace Management","text":""},{"location":"prompting/#types-of-workspaces","title":"Types of Workspaces","text":"<p>Organize your development environment with purpose-specific workspaces:</p> <ol> <li> <p>Provider-Specific YAML<pre><code>Examples:\n- OpenAI Development\n- Claude Integration\n- Local Model Testing\n</code></pre></p> </li> <li> <p>Domain-Focused YAML<pre><code>Examples:\n- Frontend Development\n- Backend Services\n- Infrastructure Management\n</code></pre></p> </li> </ol>"},{"location":"prompting/#workspace-setup-guide","title":"Workspace Setup Guide","text":"<ol> <li> <p>Initial Configuration YAML<pre><code>Steps:\n1. Navigate to Workspace Settings\n2. Create New (+) or Edit Existing\n3. Configure Base Settings:\n   - Name: [descriptive identifier]\n   - Model: [preferred LLM]\n   - Temperature: [0.0-1.0]\n</code></pre></p> </li> <li> <p>Context Setup YAML<pre><code>Required Information:\n- Project Directory: Absolute path\n- Stack Definition: Technologies used\n- Access Permissions: Required paths\n- Development Rules: Team guidelines\n</code></pre></p> </li> </ol>"},{"location":"prompting/#using-github-integration","title":"Using GitHub Integration","text":"<p>Access issue context with simple commands to the llm: Markdown<pre><code># View specific issue\nLook at github issue 42\n\n# List recent issues\nShow open issues\n\n# Reference in discussion\nRegarding issue 42, can we...\n</code></pre></p>"},{"location":"prompting/#example-vmpilot-development-prompt","title":"Example: VMPilot Development Prompt","text":"<p>Below is the actual prompt used in VMPilot's development:</p> Markdown<pre><code># Project Overview: VMPilot\nAn AI-driven system operations assistant with CLI and API interfaces.\n\n## Location and structure\n\nThe base directory is $HOME/vmpilot.  Always **cd to this directory** before looking at the files.\n\n```bash\ncd $HOME/vmpilot &amp;&amp; ls\n```\n\n\nIgnore directories not listed below.\n\n\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 source -- Documentation source files\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 user-guide\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vmpilot -- Main source code directory\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 caching\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 plugins\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 codemap\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 github_issues\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 tools -- Llm Tool implementations\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 scripts -- Integration test scripts\n    \u251c\u2500\u2500 sample_files -- file used by tests\n    \u2514\u2500\u2500 unit -- Unit tests\n        \u2514\u2500\u2500 tools\n\n\n## Architecture\n* Supports multiple deployment modes:\n  - CLI mode (vmpilot-cli)\n  - Pipeline mode (OpenWebUI compatible, port 9099)\n\n## Development Guidelines\n* Tools follow standard interface with required methods\n* Pipeline integrates with OpenWebUI specification\n\n#### /src/vmpilot/\nMain source code directory containing the core implementation.\n- **Core Files**:\n  - vmpilot.py: Main application entry point. Implements the Pipeline mode.\n  - agent.py: Core implementation for the agent\n    - Handles LLM setup and configuration\n    - Implements message processing pipeline\n    - Manages tool integration\n  - config.py: Configuration management\n  - cli.py: Command-line interface implementation\n\n#### /src/vmpilot/tools/\nTool implementations for various functionalities.\n  - CreateFileTool: Create a file\n  - EditTool: Edit a file\n  - SetupShellTool: shell tool\n\n#### /bin/\nExecution scripts:\n- cli.sh: CLI launcher\n- run.sh: Main execution script for the openwebui pipeline\n\n#### /tests/\nTest suite and testing utilities:\n- Test harnesses\n- Sample files\n- Integration tests\n\n## Key Features\n\n1. **LLM Integration**\n   - Supports multiple providers (Anthropic, OpenAI)\n   - Configurable models and parameters\n   - Streaming response capability\n\n2. **Tool System**\n   - Extensible tool framework\n   - Built-in file and system operations\n   - Error handling and result management\n\n3. **Pipeline Architecture**\n   - Message processing pipeline\n   - Asynchronous operation support\n   - State management and checkpointing\n\n4. **Development Tools**\n   - Comprehensive testing framework\n   - Deployment automation\n   - Development utilities\n\n## Testing and Development\n- Structured test suite in /tests\n- Integration test scripts\n- Sample files for testing\n\n## Common Usage Patterns\n### CLI Mode\n- cli.sh \"Show me /home\"\n- cli \"create a hello world example in /tmp/hello.py\"\n</code></pre>"},{"location":"prompting/#github-issues-as-prompts","title":"Github issues as prompts","text":"<p>To provide context about the current task, we use the <code>github issues</code> plugin.  Just ask the llm to view the issue, and it will provide the context.</p>"},{"location":"prompting/#example","title":"Example","text":"<p>When working on the VMPilot docs, I ask:</p> <p>Markdown<pre><code>Look at github issue 3, documentation.\n\n    I added a new section \u201cPrompting\u201d. I\u2019m concerned, however that experienced users will skip it because they know how to prompt. However, this page has some important info about prompting in vmpilot\n</code></pre> And the llm responds: Markdown<pre><code>I'll help analyze these points. Let me first look at issue 3 and the documentation.\n```\n$ cd /home/dror/vmpilot &amp;&amp; gh issue view 3\ntitle:  Documentation System Setup with MkDocs and GitHub Pages\nstate:  OPEN\nauthor: dror-llm\nlabels: documentation, enhancement\ncomments:   2\nassignees:  drorm\nprojects:\nmilestone:  0.1\nnumber: 3\n--\n# Documentation System Setup with MkDocs and GitHub Pages\n...\n(and 64 more lines)\nLet me address each of your points:\n\n    Regarding the \"Prompting\" section concern:\n            You're right that this is a valid concern. Since VMPilot has specific prompting requirements/features, I suggest renaming it to something more specific like \"VMPilot-Specific Prompting\" or \"VMPilot Prompt System\" to differentiate it from general LLM prompting. This makes it clear that even experienced prompt engineers should read it.\n</code></pre></p>"},{"location":"tips/","title":"VMPilot Tips","text":""},{"location":"tips/#getting-started","title":"Getting Started","text":""},{"location":"tips/#api-key-management","title":"API Key Management","text":"<p>For optimal cost control and usage tracking: 1. Create a dedicated API key for VMPilot 2. Set specific budget limits 3. Monitor usage separately from other API applications 4. Regularly review consumption patterns</p>"},{"location":"tips/#effective-communication","title":"Effective Communication","text":""},{"location":"tips/#managing-conversations","title":"Managing Conversations","text":"<p>Long conversations can reduce effectiveness. To maintain quality:</p> <ol> <li>Keep conversations focused on specific tasks</li> <li>Start new sessions for new topics</li> <li>Include relevant context when starting fresh</li> </ol>"},{"location":"tips/#task-management","title":"Task Management","text":"<p>Break down complex tasks: - Divide large tasks into smaller, manageable steps - Verify each step before proceeding - Combine manual work with LLM assistance when needed</p>"},{"location":"tips/#track-llm-changes-with-git","title":"Track LLM changes with git","text":"<p>To track changes made by the LLM, if possible, use a clean git branch. That way, you can simply do a <code>git diff</code> to see the changes made by the LLM. </p>"},{"location":"tips/#using-openwebui","title":"Using OpenWebUI","text":""},{"location":"tips/#use-workspaces","title":"Use Workspaces","text":"<p>Workspaces are powerful organizational tools that allow you to group related pipelines and prompts. Here are some example workspace categories:</p> <ul> <li>My software with OpenAI</li> <li>My software with Anthropic</li> <li>Frontend development</li> <li>Backend development</li> <li>Personal</li> </ul> <p>When setting up a workspace prompt, include:</p> <ul> <li>The root directory of your project (crucial for file operations)</li> <li>Your technology stack</li> <li>A brief project description and file structure overview</li> </ul>"},{"location":"tips/#creating-a-workspace","title":"Creating a Workspace","text":"<ol> <li>Click on \"Workspace\"</li> <li>Click the \"+\" button to create a new workspace</li> <li>Enter a name and configure the prompt and settings</li> <li>Click \"Save\"</li> </ol>"},{"location":"tips/#steps-limit-exceeded","title":"Steps limit exceeded","text":"<p>Sometimes you'll see the message: \"Sorry, need more steps to process this request. I've done 25 steps in a row. Let me know if you'd like me to continue.\" The agent has a built in limit on the number of steps that it can take in a row to prevent it from getting stuck in a loop. The number is defined in the config file as recursion_limit.  When you see this message, you can either:</p> <ul> <li>Just type \"continue\" to let the agent continue</li> <li>Break down the task into smaller steps</li> </ul>"},{"location":"tips/#llm-issues-and-error-handling","title":"LLM Issues and Error Handling","text":"<p>The LLM may run into issues when using tools. You'll see errors like:</p> <ul> <li>\"Field required [type=missing, input_value={}, input_type=dict]\"</li> <li>\"messages.1.content.1.tool_use.name: String should match pattern '^[a-zA-Z0-9_-]{1,64}$'\"}\"</li> <li>\"messages.5.content.1.tool_use.name: String should have at most 64 characters'}}\"</li> </ul>"},{"location":"tips/#why-this-happens","title":"Why This Happens","text":"<p>This mostly happens when the LLM tries to edit a file with a large amount of content or when the history becomes large: the full request is 8000 tokens or more. To resolve this try:</p> <ul> <li>Just type \"continue\". Often the LLM can recover from the error and just keep going</li> <li>Ask the llm to create a new file instead of editing a new</li> <li>Start a new shorter conversation</li> <li>Break down the task into smaller steps</li> </ul> <p>This is an ongoing issue with LLMs and hopefully will get better with time. We're also working on improving the error handling and recovery mechanisms.</p>"},{"location":"tips/#edit-your-prompt","title":"Edit your prompt","text":"<p>When you're working on a prompt, it's often helpful to edit the original or latest prompt to refine your request. This can help you get more accurate and relevant responses from the LLM.</p>"},{"location":"tips/#stop-the-llm","title":"Stop the LLM","text":"<p>Sometimes the LLM may get stuck or go in the wrong direction. Hit the \"Stop\" button to reset the LLM and start fresh.</p>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#introduction","title":"Introduction","text":"<p>VMpilot is a powerful tool that enables collaboration with Large Language Models (LLMs) in a virtual machine environment. While primarily designed for software development tasks, it can be utilized for any operation that benefits from LLM assistance in a VM context.</p>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<p>VMPilot comes with three core tools out of the box: 1. Shell Tool: Executes shell commands and scripts 2. File Editing Tool: Modifies existing files 3. File Creation Tool: Creates new files with specified content</p>"},{"location":"user-guide/#security-note","title":"Security Note","text":"<p>[!CAUTION] VMPilot operates with your user permissions. The LLM can execute any command available to your user account, including: - Reading and writing files - Installing packages - Running system commands</p> <p>Always ensure you only grant access to directories and permissions you trust the LLM to handle.</p>"},{"location":"user-guide/#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform.</li> <li>The LLM performs the task and provides the output of any commands it runs.</li> <li>Rinse and repeat.</li> </ol> <p>Example: Text Only<pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py\n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py\n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script:\n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"user-guide/#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several operation to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"user-guide/#choosing-the-provider","title":"Choosing the provider","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"user-guide/#additional-features","title":"Additional Features","text":""},{"location":"user-guide/#plugins","title":"Plugins","text":"<p>VMPilot supports various plugins to extend its functionality. See the Plugins documentation for details about available plugins and how to use them.</p> <p>Some key plugins include:</p> <ul> <li>GitHub Issues - Manage GitHub issues directly from VMPilot</li> <li>Code Map - Generate code documentation automatically. This is a work in progress.</li> </ul>"},{"location":"user-guide/#tips-and-best-practices","title":"Tips and Best Practices","text":"<p>For tips on getting the most out of VMPilot, including workspace management, prompt engineering, and general best practices, see our Tips guide.</p>"},{"location":"examples/","title":"VMPilot Examples","text":"<p>This section showcases VMPilot's capabilities through screenshots of real interactions with the system. Each example demonstrates different aspects of VMPilot's functionality.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":"Example Description Hello World Creating a simple Hello World - a basic introduction to VMPilot FizzBuzz Implementation Implementing the classic FizzBuzz programming challenge in Python Create GitHub Issue Creating a GitHub issue for a Python TODO list application TODO App Part 1 Initial implementation of a Python TODO list application from GitHub Issue #26 TODO App Part 2 Completing the implementation and testing of the Python TODO list application"},{"location":"examples/fizzbuzz/","title":"Example: FizzBuzz Implementation","text":"<p>Objective: Create a simple FizzBuzz program in Python.</p>"},{"location":"examples/fizzbuzz/#interaction","title":"Interaction","text":""},{"location":"examples/fizzbuzz/#vmpilot-features-demonstrated","title":"VMPilot Features Demonstrated","text":"<ul> <li>Available Tools: </li> <li>Create File Tool: Used to create the Python file</li> <li>Shell Tool: Used to run bash commands and make the file executable</li> <li> <p>Edit File Tool: Used to modify the code when needed</p> </li> <li> <p>Tool Interaction:</p> </li> <li>When VMPilot uses a tool, the command or result appears in bold</li> <li>Shell tool output is displayed in code blocks and truncated to 10 lines (configurable)</li> <li>Limited output visibility provides opportunities to request code improvements</li> </ul>"},{"location":"examples/fizzbuzz/#final-implementation","title":"Final Implementation","text":""},{"location":"examples/github-issue/","title":"Example: Create GitHub Issue","text":"<p>Objective: Use VMPilot to create a new GitHub issue.</p>"},{"location":"examples/github-issue/#workflow","title":"Workflow","text":""},{"location":"examples/github-issue/#step-1-initial-request-and-planning","title":"Step 1: Initial Request and Planning","text":"<ul> <li>We begin by telling VMPilot that we want to create a GitHub issue</li> <li>Note that we specifically instruct it not to create files or the issue itself initially</li> <li>This is because VMPilot is designed to take action, and we first want to discuss and plan</li> </ul>"},{"location":"examples/github-issue/#step-2-issue-creation-process","title":"Step 2: Issue Creation Process","text":"<ul> <li>After sufficient planning and back-and-forth to ensure all details are correct, we instruct VMPilot to create the issue</li> <li>The process involves several steps:</li> <li>VMPilot examines the issue plugin to understand how to create an issue</li> <li>It checks the feature template to identify required fields</li> <li>It runs the appropriate GitHub CLI command to create the issue</li> <li>Finally, it reports back on the operation's success</li> </ul>"},{"location":"examples/github-issue/#key-points","title":"Key Points","text":"<ul> <li>VMPilot can interact with GitHub's API through the GitHub CLI</li> <li>The collaborative planning process ensures the issue meets requirements before creation</li> <li>The final result can be verified on GitHub: Issue #26</li> <li>This example demonstrates VMPilot's ability to integrate with external tools and services</li> </ul>"},{"location":"examples/hello-world/","title":"Example: Hello World","text":"<p>Objective: Create and run a Python script that displays the current date and time.</p>"},{"location":"examples/hello-world/#interaction","title":"Interaction","text":""},{"location":"examples/hello-world/#notes","title":"Notes","text":"<p>If you've used ChatGPT or Claude, this interface should be familiar:</p> <ul> <li>On the top left, you can select your preferred model</li> <li>The standard chat interface displays your request and VMPilot's response</li> <li>In the response, you can clearly see the actions taken by VMPilot:<ul> <li>Created /tmp/hello.py - VMPilot creates the Python file</li> <li>Running a bash command: $ python3 /tmp/hello.py - VMPilot executes the script</li> <li>The output of the command is displayed in a formatted code block</li> </ul> </li> </ul> <p>This simple example demonstrates how VMPilot can create files and execute commands based on natural language instructions.</p>"},{"location":"examples/template/","title":"Example: [Title]","text":"<p>Objective: [Brief one-line description of what this example demonstrates]</p>"},{"location":"examples/template/#interaction","title":"Interaction","text":""},{"location":"examples/template/#outcome","title":"Outcome","text":""},{"location":"examples/template/#key-points","title":"Key Points","text":"<ul> <li>[Highlight important aspect of this example]</li> <li>[Explain what users can learn from this demonstration]</li> <li>[Note any specific VMPilot capabilities shown]</li> <li>[Include any troubleshooting tips if relevant]</li> </ul>"},{"location":"examples/todo1/","title":"Example: Todo List Application (Part 1)","text":"<p>Objective: Initial implementation of Issue #26: Create a Python todo list application</p>"},{"location":"examples/todo1/#context","title":"Context","text":"<ul> <li>In the previous example, we created GitHub Issue #26: Create a Python todo app</li> <li>We can now refer to this issue directly in our conversation with VMPilot</li> <li>Note: We initially ask VMPilot to discuss the issue before creating any files, to establish a clear plan</li> </ul>"},{"location":"examples/todo1/#initial-planning","title":"Initial Planning","text":"<ul> <li>It started above by looking at the issue and some files, and suggests a comprehensive plan to implement the issue.</li> <li>The plan looks good overall, but needs refining to save the data to a JSON file. </li> <li> <p>The LLM starts to implement the plan.</p> </li> <li> <p>And I ask it to run the app to test it.</p> </li> </ul> <p></p> <p></p> <ul> <li>The testing looks good, but I noticed that the JSON file is in the root of the project, and I wanted it in the same directory as the app. So I ask the LLM to fix that and review the README.</li> </ul> <p></p> <p></p> <p></p> <p></p>"},{"location":"examples/todo2/","title":"Example: Todo List Application (Part 2)","text":"<p>Objective: Complete implementation of Issue #26: Python todo list application</p>"},{"location":"examples/todo2/#context","title":"Context","text":"<ul> <li>In Part 1, we began implementing the TODO app based on GitHub Issue #26</li> <li>This example demonstrates how to complete the implementation, verify functionality, and update documentation</li> <li>By starting with \"look at issue #26\", we provide VMPilot with the necessary context</li> <li>The GitHub issue contains most requirements, so detailed explanations aren't needed in our prompts</li> </ul> <ul> <li>Until now the LLM has been gathering information about the task. It looks at the github issue and various files. Now it starts to act.</li> <li> <p>It tests the CRUD opeations: Create, Read, Update, Delete.  </p> </li> <li> <p>Notice that we're getting the message: Sorry, need more steps to process this request. I've done 25 steps in a row. Let me know if you'd like me to continue. This is a safety mechanism to make sure the LLM is not stuck in a loop. The number is configurable. Simply type \"continue\" and the LLM will go on as in this example.  </p> </li> <li> <p>And that's it. We have a working todo app with CRUD operations and a README file that describes how to use it.</p> </li> <li>We skipped some steps/screenshots to keep the example short. </li> </ul>"},{"location":"plugins/overview/","title":"Plugins","text":"<p>VMPilot uses a unique text-based plugin system that extends LLM functionality without requiring traditional code-based implementations. This approach makes plugins easy to add, remove, and maintain.</p>"},{"location":"plugins/overview/#how-plugins-work","title":"How Plugins Work","text":"<p>Instead of using code-based integrations, VMPilot plugins work by injecting the plutin's directory README.md that lists the plugins into the main prompt. When the llm needs to access a plugin, it reads the README.md for that plugin and knows what actions are available.</p> <p>For example, the <code>github_issues</code> plugin enables GitHub issue management through simple text commands. This plugin could be easily replaced with alternatives (like a Jira plugin) by swapping the plugin configuration.</p>"},{"location":"plugins/overview/#current-plugin-system","title":"Current Plugin System","text":"<p>The system currently looks like this: Markdown<pre><code># Available plugins\n\n# Codemap\ndirectory: codemap\nCreates documentation by scanning the code and generating a doc per source file.\n\n# Github\n\ndirectory: github\\_issues\n- To view or list issues, use \"cd $rootDir &amp;&amp; gh issue view $number\" or \"gh issue list\". Always include the \"gh\" command.\n- To create an issue view the README.md file for instructions.\n</code></pre></p>"},{"location":"plugins/overview/#managing-plugins","title":"Managing Plugins","text":"<p>Enabling or disabling plugins is straightforward - simply add or remove their entries from the main README.md file.</p>"},{"location":"plugins/overview/#creating-new-plugins","title":"Creating New Plugins","text":"<p>To create a new plugin: 1. Create a directory in the plugins directory 2. Create a README.md file using template.md from the plugins directory as a guide 3. Add your plugin's entry to the main README.md file in the plugins directory 4. Test the plugin functionality with various prompts</p> <p>For examples of existing plugins, see the <code>codemap</code> and <code>github_issues</code> implementations in the plugins directory.</p>"}]}