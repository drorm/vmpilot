{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VMPilot Documentation","text":"<p>[!CAUTION] Only run VMPilot in a dedicated virtual machine. Never run this on your local machine as it allows AI/LLM to execute arbitrary commands which can be dangerous. There are security risks including potential external world interactions that could be exploited by attackers.</p>"},{"location":"#what-is-vmpilot","title":"What is VMPilot?","text":"<p>VMPilot provides a way to interact with an AI agent to perform tasks in a virtual machine. It is focused on pair programming, where the AI can help you with coding tasks, but it can also be used for other system operations. While using a familiar chat interface (thanks to OpenWebUI), it provides advanced capabilities by executing multiple commands in the virtual machine to accomplish your requested tasks.</p> <p>Using natural language, you can ask VMPilot to: - Write and modify code - Execute system commands - Manage files and directories - Handle GitHub issues and repositories - Perform complex multi-step operations</p>"},{"location":"#available-interfaces","title":"Available Interfaces","text":"<p>VMPilot can be used in two ways: - Web Interface: Full-featured interface through OpenWebUI integration  - CLI Mode: Direct command-line interface for quick interactions. This is mostly used for testing and debugging.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Intelligent Command Execution: </li> <li>Natural language understanding of your intent</li> <li>Smart handling of complex multi-step operations</li> <li> <p>Real-time feedback and error handling</p> </li> <li> <p>Development Tools:</p> </li> <li>Code writing and modification</li> <li>File management and editing</li> <li> <p>GitHub integration for issue management</p> </li> <li> <p>Flexible LLM Support:</p> </li> <li>Works with multiple providers (Anthropic, OpenAI)</li> <li>Configurable models and parameters</li> <li>Streaming response capability</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Installation Guide - Complete setup instructions</li> <li>Configuration Guide - Configure VMPilot for your needs</li> <li>User Guide - Learn the basics of using VMPilot</li> </ol>"},{"location":"#documentation-sections","title":"Documentation Sections","text":""},{"location":"#essential-guides","title":"Essential Guides","text":"<ul> <li>Configuration Guide - Setting up VMPilot</li> <li>Installation Guide - Detailed installation steps</li> <li>User Guide - Basic usage and concepts</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Prompting Guide - How to effectively interact with VMPilot</li> <li>Plugins System - Extending VMPilot's capabilities</li> <li>GitHub Integration - Working with GitHub repositories</li> <li>Tips and Best Practices - Advanced usage tips</li> </ul>"},{"location":"#security-considerations","title":"Security Considerations","text":"<p>VMPilot has powerful capabilities that require careful consideration:</p> <ul> <li>Only run in isolated virtual machines</li> <li>Keep API keys secure and use fine-grained access tokens</li> <li>Follow security best practices when exposing endpoints</li> <li>Regularly monitor and audit command execution</li> <li>Use minimal permissions for GitHub and other integrations</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>VMPilot provides a powerful command-line interface that allows you to interact with the tool directly from your terminal.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using the CLI is:</p> Bash<pre><code>cli.sh \"your command here\"\n</code></pre> <p>For example: Bash<pre><code>cli.sh \"Show me the contents of /etc/hosts\"\ncli.sh \"Create a new Python script that prints Hello World\"\ncli.sh  cli.sh  `cat reqeust.sh`\n</code></pre></p> <p>Remember to enclose your command in quotes to ensure that it is passed as a single argument to the CLI. In the last example, we used backticks to execute a command and pass its output as an argument to the CLI.</p>"},{"location":"cli/#command-line-options","title":"Command Line Options","text":"<p>The CLI supports several command line options to customize its behavior:</p> Text Only<pre><code>usage: cli.sh [-h] [-t TEMPERATURE] [-p {anthropic,openai}] [-d] request\n\npositional arguments:\n  request               request to the llm\n\noptions:\n  -h, --help           Show this help message and exit\n  -t TEMPERATURE,      Temperature for response generation (default: 0.7)\n  --temperature\n  -p {anthropic,openai},\n  --provider          API provider to use (default: anthropic)\n  -d, --debug         Enable debug mode\n</code></pre>"},{"location":"cli/#temperature","title":"Temperature","text":"<p>The temperature parameter controls the randomness in the response generation. Higher values (e.g., 0.8) make the output more creative but potentially less focused, while lower values (e.g., 0.2) make it more deterministic and focused. As a rule you should not provide a temperature value, since these are set by the API provider. For testing we use a value of 0 so that the output is deterministic.</p> <p>Example: Bash<pre><code>cli.sh -t 0.3 \"Write a Python function to calculate factorial\"\n</code></pre></p>"},{"location":"cli/#provider-selection","title":"Provider Selection","text":"<p>You can choose between different LLM providers: - anthropic (default) - openai</p> <p>Example: Bash<pre><code>cli.sh -p openai \"Explain how to use the ls command\"\n</code></pre></p>"},{"location":"cli/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode to see detailed logging information, which can be helpful for troubleshooting:</p> Bash<pre><code>cli.sh -d \"Show system information\"\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":"<p>Here are some common usage examples:</p> <ol> <li> <p>Basic system operations: Bash<pre><code>cli.sh \"Show me all Python files in the current directory\"\ncli.sh \"Create a new directory called 'test' and add a README file\"\n</code></pre></p> </li> <li> <p>File editing: Bash<pre><code>cli.sh \"Change the word 'error' to 'warning' in log.txt\"\ncli.sh \"Add a new function to myscript.py\"\n</code></pre></p> </li> <li> <p>Using different providers with custom temperature: Bash<pre><code>cli.sh -p openai -t 0.5 \"Optimize this Python script for performance\"\n</code></pre></p> </li> </ol>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI will display error messages when: - The command execution fails - There are permission issues - The LLM provider is not properly configured - Invalid arguments are provided</p> <p>If you encounter errors, try: 1. Using debug mode (-d) to get more information 2. Checking your API provider configuration 3. Verifying you have the necessary permissions for the requested operation</p>"},{"location":"configuration/","title":"Configuration Guide","text":""},{"location":"configuration/#overview","title":"Overview","text":"<p>VMPilot uses a flexible configuration system that supports multiple locations for config files and various settings for LLM providers and model parameters.</p>"},{"location":"configuration/#configuration-file-locations","title":"Configuration File Locations","text":"<p>VMPilot looks for configuration in the following locations (in order): 1. Path specified in VMPILOT_CONFIG environment variable 2. ./config.ini in the project directory 3. config.ini in the current working directory 4. ~/.config/vmpilot/config.ini</p>"},{"location":"configuration/#configuration-file-structure","title":"Configuration File Structure","text":"<p>The configuration file (config.ini) should contain the following sections:</p>"},{"location":"configuration/#general","title":"[general]","text":"<ul> <li>default_provider: The default LLM provider to use (anthropic or openai)</li> <li>tool_output_lines: Number of lines to show in tool output</li> </ul>"},{"location":"configuration/#model","title":"[model]","text":"<ul> <li>recursion_limit: Maximum number of recursive steps the model can take</li> </ul>"},{"location":"configuration/#inference","title":"[inference]","text":"<ul> <li>temperature: Model temperature setting</li> <li>max_tokens: Maximum tokens for model responses</li> </ul>"},{"location":"configuration/#anthropic-openai","title":"[anthropic] / [openai]","text":"<p>Provider-specific settings: - default_model: Default model to use for this provider - api_key_path: Path to API key file - api_key_env: Environment variable name for API key - beta_flags: Optional comma-separated key:value pairs for beta features</p>"},{"location":"configuration/#example-configuration","title":"Example Configuration","text":"INI<pre><code>[general]\ndefault_provider = anthropic\ntool_output_lines = 15\n\n[model]\nrecursion_limit = 25\n\n[inference]\ntemperature = 0.7\nmax_tokens = 2000\n\n[anthropic]\ndefault_model = claude-2\napi_key_path = ~/.anthropic_key\napi_key_env = ANTHROPIC_API_KEY\n\n[openai]\ndefault_model = gpt-4\napi_key_path = ~/.openai_key\napi_key_env = OPENAI_API_KEY\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<ul> <li>VMPILOT_CONFIG: Optional path to configuration file</li> <li>Provider-specific API key variables (as specified in config.ini)</li> </ul>"},{"location":"dns_ssl_setup/","title":"DNS and SSL Configuration Guide","text":""},{"location":"dns_ssl_setup/#overview","title":"Overview","text":"<p>This guide covers setting up secure access to your OpenWebUI and VMPilot Pipeline services using DNS and SSL certificates. We'll walk through setting up dynamic DNS and configuring Caddy as a reverse proxy with automatic SSL certificate management. This is optional and not only recommended for secure access to your services, it'll make your life easier to not have to deal with browser warnings about insecure connections.</p> <p>[!CAUTION] While I tried to make this guide somewhat comprehensive, check with Claude or GPT for any additional steps or configurations that might be needed for your specific setup.</p>"},{"location":"dns_ssl_setup/#dynamic-dns-setup","title":"Dynamic DNS Setup","text":"<p>If you're running these services from a location without a static IP which is often the case with home servers, you'll need to set up dynamic DNS to ensure your domain/subdomain always points to the correct IP address.</p> <ol> <li>Choose a Dynamic DNS Provider</li> <li> <p>Options include No-IP, DuckDNS, or Cloudflare</p> </li> <li> <p>Register for Dynamic DNS</p> </li> <li>Create an account at your chosen provider</li> <li>Register your desired subdomain</li> <li> <p>Note down your token/credentials</p> </li> <li> <p>Configure Dynamic DNS Client</p> </li> <li> <p>follow the instructions for your chosen provider</p> </li> <li> <p>Start and Enable the Service</p> </li> </ol>"},{"location":"dns_ssl_setup/#caddy-server-setup","title":"Caddy Server Setup","text":"<p>Caddy is a lightweight web server that can handle automatic SSL certificate management and reverse proxying. We'll use Caddy to set up secure access to OpenWebUI and VMPilot Pipeline.</p> <ol> <li> <p>Install Caddy    Bash<pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy\n</code></pre></p> </li> <li> <p>Configure Caddy    Create a Caddyfile:    Bash<pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></p> </li> </ol> <p>Basic configuration for OpenWebUI and Pipeline:    Text Only<pre><code>webui.yourdomain.com {\n    reverse_proxy localhost:8080\n}\n\npipeline.yourdomain.com {\n    reverse_proxy localhost:9099\n}\n</code></pre></p> <ol> <li>Start and Enable Caddy    Bash<pre><code>sudo systemctl restart caddy\nsudo systemctl enable caddy\n</code></pre></li> </ol>"},{"location":"dns_ssl_setup/#dns-configuration","title":"DNS Configuration","text":"<ol> <li>Set up A/AAAA Records</li> <li>Point your domain/subdomain to your server's IP</li> <li> <p>If using dynamic DNS, this is handled automatically</p> </li> <li> <p>Verify DNS Propagation    Bash<pre><code>dig webui.yourdomain.com\ndig pipeline.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Check Caddy Status    Bash<pre><code>sudo systemctl status caddy\n</code></pre></p> </li> <li> <p>View Caddy Logs    Bash<pre><code>sudo journalctl -u caddy\n</code></pre></p> </li> <li> <p>Verify SSL Certificates    Bash<pre><code>curl -vI https://webui.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#next-steps","title":"Next Steps","text":"<p>Once DNS and SSL are configured, proceed to Installation Guide for setting up OpenWebUI and VMPilot.</p>"},{"location":"github_issues/","title":"GitHub Issues Plugin","text":"<p>The GitHub Issues plugin enables VMPilot to interact with GitHub issues directly through the GitHub CLI (<code>gh</code>). This plugin provides a seamless way to view, create, and manage GitHub issues without leaving your VMPilot environment.</p>"},{"location":"github_issues/#prerequisites","title":"Prerequisites","text":"<p>Before using the GitHub Issues plugin, ensure you have: - GitHub CLI (<code>gh</code>) installed on your system - Authenticated GitHub CLI access (<code>gh auth login</code>)</p>"},{"location":"github_issues/#features","title":"Features","text":""},{"location":"github_issues/#viewing-issues","title":"Viewing Issues","text":"<p>You can view issues using simple commands like: Text Only<pre><code>show me issue 3\n</code></pre> or Text Only<pre><code>what's the status of issue #5\n</code></pre></p> <p>The plugin will automatically: 1. Navigate to the project root directory 2. Fetch and display the issue information</p>"},{"location":"github_issues/#creating-issues","title":"Creating Issues","text":"<p>To create a new issue, you can use natural language requests like: Text Only<pre><code>create a github issue titled \"Add logging feature\" with label \"enhancement\"\n</code></pre></p> <p>The plugin will: 1. Review the appropriate issue template 2. Gather any required information through conversation 3. Create the issue using the GitHub CLI</p>"},{"location":"github_issues/#common-operations","title":"Common Operations","text":"<p>The plugin supports all basic GitHub issue operations: - Listing all issues - Creating new issues - Viewing specific issues - Closing issues - Reopening issues</p>"},{"location":"github_issues/#best-practices","title":"Best Practices","text":"<ol> <li>Be Specific: When creating issues, provide clear titles and descriptions</li> <li>Use Labels: Include relevant labels to categorize issues properly</li> <li>Template Compliance: Follow any issue templates configured in the repository</li> <li>Confirmation: The plugin will seek confirmation before creating or modifying issues</li> </ol>"},{"location":"github_issues/#technical-details","title":"Technical Details","text":"<p>The plugin operates by: 1. Using the project's root directory as the base for all operations 2. Leveraging the GitHub CLI for all interactions 3. Following repository-specific templates and guidelines</p>"},{"location":"github_issues/#example-usage","title":"Example Usage","text":"<p>Here are some example interactions:</p> <ol> <li> <p>Viewing an issue: Text Only<pre><code>show me issue #3\n</code></pre></p> </li> <li> <p>Creating an issue: Text Only<pre><code>create an issue for a new feature request:\ntitle: Add dark mode support\nlabel: enhancement\n</code></pre></p> </li> <li> <p>Listing recent issues: Text Only<pre><code>show me the open issues\n</code></pre></p> </li> </ol> <p>The plugin will handle all the necessary GitHub CLI commands and provide appropriate feedback for each operation.</p>"},{"location":"installation/","title":"VMPilot Installation Guide","text":"<p>This guide provides comprehensive instructions for setting up VMPilot in your environment.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker container with:</li> <li>ubuntu 22.04 or later</li> <li>python 3.11 or later</li> </ul> <p>Before proceeding with this installation guide, it is recommended that you complete the DNS and SSL Setup to configure secure access to your services.</p> <p>VMPilot in its current form is meant for folks familiar with Docker and Linux. So rather than provide a docker container, we provide the instructions.</p>"},{"location":"installation/#1-set-up-your-virtual-machine","title":"1. Set up your virtual machine","text":"<p>Set up a virtual machine with your standard configuration. You'll be sharing this machine with VMPilot, so set it up in a way that feels comfortable to you.</p> <ul> <li>gvisor is recommended for security. Enable your container runtime to use gvisor.</li> <li>Once you have your virtual machine set up, you can proceed with the installation.</li> </ul>"},{"location":"installation/#2-install-the-apps-on-your-virtual-machine","title":"2. Install the apps on your virtual machine.","text":""},{"location":"installation/#3-installing-openwebui","title":"3. Installing OpenWebUI","text":"<p>OpenWebUI serves as the frontend interface for VMPilot.</p> <p>Follow the instructions on the OpenWebUI GitHub repository</p> Bash<pre><code>pip install open-webui\n</code></pre> <p>and then run the following command:</p> Bash<pre><code>open-webui serve\n</code></pre> <p>You can, of course, follow one of the other methods suggested in the OpenWebUI documentation.</p>"},{"location":"installation/#31-create-a-new-openwebui-user","title":"3.1 Create a new OpenWebUI user","text":"<p>In a browser, navigate to the OpenWebUI interface at your domain or localhost Create a new user on OpenWebUI which, as the first user, will make you the admin user.</p>"},{"location":"installation/#4-install-openwebui-pipelines","title":"4. Install OpenWebUI Pipelines","text":"<p>OpenWebUI Pipelines is required for VMPilot integration.</p> Bash<pre><code>cd ~\ngit clone https://github.com/open-webui/pipelines\n</code></pre> <p>This will clone the repository to your home directory. This is the default location for VMPilot to look for the pipelines.</p>"},{"location":"installation/#41-install-dependencies","title":"4.1 Install dependencies:","text":"<p>Bash<pre><code>pip install -r requirements.txt\n</code></pre> You don't need to run the pipelines server, as VMPIlot will run it.</p>"},{"location":"installation/#5-installing-vmpilot","title":"5. Installing VMPilot","text":""},{"location":"installation/#51-server-installation","title":"5.1 Server Installation","text":"<p>Clone the VMPilot repository: Bash<pre><code>cd ~\ngit clone https://github.com/yourusername/vmpilot.git\ncd vmpilot\n</code></pre></p> <p>Install dependencies: Bash<pre><code>pip install -r requirements.txt\n</code></pre></p> <p>Set up your credentials. The defaults are: - Anthropic: ~/.anthropic/api_key - OpenAI: ~/.openai</p>"},{"location":"installation/#52-check-the-configuration","title":"5.2 Check the configuration","text":"<p>Look at vmpilot/src/vmpilot/config.ini and make sure the configuration is correct for your setup. Alternatively you can set the environment variable VMPILOT_CONFIG to the path of your configuration file.</p>"},{"location":"installation/#53-start-vmpilot","title":"5.3 Start VMPilot","text":"Bash<pre><code>~/vmpilot/bin/run.sh\n</code></pre>"},{"location":"installation/#32-openwebui-client-configuration","title":"3.2 OpenWebUI Client Configuration","text":"<ol> <li>Access the OpenWebUI interface at your domain or localhost</li> </ol> <p>2 Open OpenWebUI in your browser 2.1 Open OpenWebUI in your browser 2.2 Click on your user name in the bottom left corner 3.3 Click on Admin Panel 3.4 Click on connections</p> <ol> <li>Add VMPilot Connection:</li> <li>URL: http://localhost:9099 and the password</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Enable the pipeline:</p> </li> <li>Go to Pipelines tab</li> <li>Find the above url</li> <li>Enter the keys for the provider you want to use: OpenAI, Anthropic, or both.</li> <li>Click \"Save\"</li> </ol> <p>Note: Because the VMPilot pipeline is a manifold pipeline, you'll see two models in the pipeline list: - VMPilot PipelineAnthropic (Claude) - VMPilot PipelineOpenAI (GPT-4o)</p> <p>Claude is currently the preferred model for VMPilot, since it: - Seems to handle code better. - Is relatively affordable and fast when caching is handled correctly. VMPIlot caches the conversation history, so the model doesn't have to relearn everything every time. - Has been tested more extensively.</p>"},{"location":"installation/#4-verification","title":"4. Verification","text":"<p>To verify your installation:</p> <ol> <li>Open OpenWebUI in your browser. Choose one of the above models and start a conversation.</li> <li>Try a simple command like \"Show me /home\"</li> </ol>"},{"location":"installation/#5-troubleshooting","title":"5 Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Connection refused:</li> <li>Check if VMPilot server is running</li> <li>Verify port configurations</li> <li> <p>Check firewall settings</p> </li> <li> <p>Authentication errors:</p> </li> <li>Verify API key in the UI</li> <li> <p>Check OpenWebUI pipeline configuration</p> </li> <li> <p>Model not found:</p> </li> <li>Go to the connection settings as described above, and save the connection again.</li> <li>Go to the pipeline settings and save the pipeline again.</li> <li>Edit the workplace and make sure the pipeline is selected.</li> </ol>"},{"location":"plugins/","title":"Plugins","text":"<p>VMPilot plugins provide a unique approach to extending LLM functionality through text-based configuration, rather than traditional code-based plugins. This means that it is quite easy to add or remove plugins from the system, and the plugins themselves are simple to create and maintain.</p> <p>We use, for instance, the <code>github issues</code> plugin to manage issues in the VMPilot project. It should be relatively easy to replace it with a different plugin, such as a Jira plugin, if needed.</p>"},{"location":"plugins/#how-plugins-work","title":"How Plugins Work","text":"<p>The system injects each plugin's README.md content into the LLM's prompt. Currently, the plugin system looks like this: Markdown<pre><code># Available plugins\n\n# Codemap\ndirectory: codemap\nCreates documentation by scanning the code and generating a doc per source file.\n\n# Github\n\ndirectory: github\\_issues\n- To view or list issues, use \"cd $rootDir &amp;&amp; gh issue view $number\" or \"gh issue list\". Always include the \"gh\" command.\n- To create an issue view the README.md file for instructions.\n</code></pre></p>"},{"location":"plugins/#managing-plugins","title":"Managing Plugins","text":"<p>Enabling or disabling plugins is straightforward - simply add or remove their entries from the README.md file.</p>"},{"location":"plugins/#creating-new-plugins","title":"Creating New Plugins","text":"<p>To create a new plugin: 1. Create a directory in the plugins directory 2. Create a README.md file using template.md from the plugins directory as a guide 3. Add your plugin's entry to the main README.md file in the plugins directory 4. Test the plugin functionality with various prompts</p> <p>For examples of existing plugins, see the <code>codemap</code> and <code>github_issues</code> implementations in the plugins directory.</p>"},{"location":"prompting/","title":"VMPilot Prompting System","text":""},{"location":"prompting/#overview","title":"Overview","text":"<p>Whenever you start a conversation with an LLM, it has no context or memory of previous interactions. You need to provide context and direction.  VMPilot uses a multi-level prompting system to ensure the LLM has the necessary context to assist effectively.</p>"},{"location":"prompting/#core-concepts","title":"Core Concepts","text":""},{"location":"prompting/#1-project-context","title":"1. Project Context","text":"<p>Using OpenWebUI workspaces, we provide:</p> <ul> <li>Project root directory location</li> <li>Project structure and overview</li> <li>Technology stack information</li> <li>Development guidelines</li> </ul>"},{"location":"prompting/#2-task-context","title":"2. Task Context","text":"<p>Through Github issues integration:</p> <ul> <li>Current task details and requirements</li> <li>Related discussions and context</li> <li>Project milestones and labels</li> </ul>"},{"location":"prompting/#working-with-openwebui-workspaces","title":"Working with OpenWebUI Workspaces","text":"<p>Workspaces in VMPilot help organize different aspects of your development:</p> <ul> <li>Project-specific workspaces (e.g., OpenAI VMPilot, Claude VMPilot)</li> <li>Development focus areas (Frontend, Backend)</li> <li>Personal workspaces</li> </ul>"},{"location":"prompting/#essential-workspace-components","title":"Essential Workspace Components","text":"<p>When setting up a workspace prompt, include: - Project root directory (crucial for file operations) - Technology stack details - Project description and structure - Development guidelines</p>"},{"location":"prompting/#setting-up-a-workspace","title":"Setting Up a Workspace","text":"<ol> <li>Click on \"Workspace\"</li> <li>Click the \"+\" button to create a new workspace</li> <li>Enter a name and configure settings</li> <li>Add your project prompt</li> <li>Click \"Save\"</li> </ol>"},{"location":"prompting/#using-github-issues-for-context","title":"Using Github Issues for Context","text":"<p>The Github issues plugin provides task-specific context to the LLM. Simply ask to view an issue: Bash<pre><code>Look at github issue &lt;number&gt;\n</code></pre></p>"},{"location":"prompting/#examples","title":"Examples","text":""},{"location":"prompting/#sample-project-prompt","title":"Sample Project Prompt","text":"<p>The following is the actual VMPilot project prompt:</p>"},{"location":"prompting/#sample-prompt","title":"Sample prompt","text":"<p>This is the VMPilot prompt used to develop the VMPilot project. </p> Markdown<pre><code># Project Overview: VMPilot\nAn AI-driven system operations assistant with CLI and API interfaces.\n\n## Location and structure\n\nThe base directory is $HOME/vmpilot.  Always **cd to this directory** before looking at the files.\n\n```bash\ncd $HOME/vmpilot &amp;&amp; ls\n```\n\n\nIgnore directories not listed below.\n\n\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 source -- Documentation source files\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 user-guide\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vmpilot -- Main source code directory\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 caching\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 plugins\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 codemap\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 github_issues\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 tools -- Llm Tool implementations\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 scripts -- Integration test scripts\n    \u251c\u2500\u2500 sample_files -- file used by tests\n    \u2514\u2500\u2500 unit -- Unit tests\n        \u2514\u2500\u2500 tools\n\n\n## Architecture\n* Supports multiple deployment modes:\n  - CLI mode (vmpilot-cli)\n  - Pipeline mode (OpenWebUI compatible, port 9099)\n\n## Development Guidelines\n* Tools follow standard interface with required methods\n* Pipeline integrates with OpenWebUI specification\n\n#### /src/vmpilot/\nMain source code directory containing the core implementation.\n- **Core Files**:\n  - vmpilot.py: Main application entry point. Implements the Pipeline mode.\n  - agent.py: Core implementation for the agent\n    - Handles LLM setup and configuration\n    - Implements message processing pipeline\n    - Manages tool integration\n  - config.py: Configuration management\n  - cli.py: Command-line interface implementation\n\n#### /src/vmpilot/tools/\nTool implementations for various functionalities.\n  - CreateFileTool: Create a file\n  - EditTool: Edit a file\n  - SetupShellTool: shell tool\n\n#### /bin/\nExecution scripts:\n- cli.sh: CLI launcher\n- run.sh: Main execution script for the openwebui pipeline\n\n#### /tests/\nTest suite and testing utilities:\n- Test harnesses\n- Sample files\n- Integration tests\n\n## Key Features\n\n1. **LLM Integration**\n   - Supports multiple providers (Anthropic, OpenAI)\n   - Configurable models and parameters\n   - Streaming response capability\n\n2. **Tool System**\n   - Extensible tool framework\n   - Built-in file and system operations\n   - Error handling and result management\n\n3. **Pipeline Architecture**\n   - Message processing pipeline\n   - Asynchronous operation support\n   - State management and checkpointing\n\n4. **Development Tools**\n   - Comprehensive testing framework\n   - Deployment automation\n   - Development utilities\n\n## Testing and Development\n- Structured test suite in /tests\n- Integration test scripts\n- Sample files for testing\n\n## Common Usage Patterns\n### CLI Mode\n- cli.sh \"Show me /home\"\n- cli \"create a hello world example in /tmp/hello.py\" \n</code></pre>"},{"location":"prompting/#github-issues-as-prompts","title":"Github issues as prompts","text":"<p>To provide context about the current task, we use the <code>github issues</code> plugin.  Just ask the llm to view the issue, and it will provide the context. </p>"},{"location":"prompting/#example","title":"Example","text":"<p>When working on the VMPilot docs, I ask:</p> <p>Markdown<pre><code>Look at github issue 3, documentation.   \n\n    I added a new section \u201cPrompting\u201d. I\u2019m concerned, however that experienced users will skip it because they know how to prompt. However, this page has some important info about prompting in vmpilot   \n</code></pre> And the llm responds: Markdown<pre><code>I'll help analyze these points. Let me first look at issue 3 and the documentation.\n```\n$ cd /home/dror/vmpilot &amp;&amp; gh issue view 3 \ntitle:  Documentation System Setup with MkDocs and GitHub Pages\nstate:  OPEN\nauthor: dror-llm\nlabels: documentation, enhancement\ncomments:   2\nassignees:  drorm\nprojects:   \nmilestone:  0.1\nnumber: 3\n--\n# Documentation System Setup with MkDocs and GitHub Pages\n...\n(and 64 more lines)\nLet me address each of your points: \n\n    Regarding the \"Prompting\" section concern: \n            You're right that this is a valid concern. Since VMPilot has specific prompting requirements/features, I suggest renaming it to something more specific like \"VMPilot-Specific Prompting\" or \"VMPilot Prompt System\" to differentiate it from general LLM prompting. This makes it clear that even experienced prompt engineers should read it.\n</code></pre></p>"},{"location":"tips/","title":"Tips and Best Practices","text":""},{"location":"tips/#create-a-separate-api-key-for-vmpilot","title":"Create a Separate API Key for VMPilot","text":"<p>When you first start using VMPilot, it's recommended to create a dedicated API key to manage costs effectively. This allows you to: - Set a specific budget for VMPilot usage - Monitor VMPilot-specific API consumption - Keep your other API usage separate</p>"},{"location":"tips/#managing-chat-length","title":"Managing Chat Length","text":"<p>As conversations grow longer, the LLM's responses may become less focused and effective. When this happens: - Start a new chat session - Reuse or update your original prompt - Copy relevant context from the previous conversation if needed</p>"},{"location":"tips/#working-with-llms-effectively","title":"Working with LLMs Effectively","text":"<p>LLMs can be remarkably capable but also occasionally unpredictable. To get the best results:</p> <ul> <li>Read about prompt engineering. It's a skill that takes time to develop but it's worth it.</li> <li>Don't ask the llm to do too much at once. Break down the task into smaller tasks.</li> <li>Sometimes, you just need to do the task yourself, at least part of it. </li> </ul>"},{"location":"tips/#using-openwebui","title":"Using OpenWebUI","text":""},{"location":"tips/#using-workspaces","title":"Using Workspaces","text":"<p>Workspaces are powerful organizational tools that allow you to group related pipelines and prompts. Here are some example workspace categories: - My software with OpenAI - My software with Anthropic - Frontend development - Backend development - Personal</p> <p>When setting up a workspace prompt, include: - The root directory of your project (crucial for file operations) - Your technology stack - A brief project description and file structure overview</p>"},{"location":"tips/#creating-a-workspace","title":"Creating a Workspace","text":"<ol> <li>Click on \"Workspace\"</li> <li>Click the \"+\" button to create a new workspace</li> <li>Enter a name and configure the prompt and settings</li> <li>Click \"Save\"</li> </ol>"},{"location":"tips/#edit-your-prompt","title":"Edit your prompt","text":"<p>When you're working on a prompt, it's often helpful to edit the original or latest prompt to refine your request. This can help you get more accurate and relevant responses from the LLM.</p>"},{"location":"tips/#stop-the-llm","title":"Stop the LLM","text":"<p>Sometimes the LLM may get stuck or go in the wrong direction. Hit the \"Stop\" button to reset the LLM and start fresh.</p>"},{"location":"user-guide/","title":"User guide","text":""},{"location":"user-guide/#introduction","title":"Introduction","text":"<p>VMpilot is a tool that allows you to collaborate with an LLM primarily for software development, but can be used for any tasks that benefits from an LLM operating in a virtual machine.</p>"},{"location":"user-guide/#basic-usage","title":"Basic usage","text":"<p>Out of the box, VMPilot has several tools - A shell tool where it can run shell commands - A file editing tool where it can edit files - A file creation tool where it can create files</p> <p>Since it can run a shell command, it can run any command that you can run in a shell. This includes running scripts, installing packages, and running any other command that you can run in a shell.</p> <p>[!CAUTION] Only give the llm access to files and permissions that you are comfortable with. The llm can run any command that you can run in a shell as the logged in user, so it can potentially do anything that you can do in a shell.</p>"},{"location":"user-guide/#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform.</li> <li>The LLM performs the task and provides the output of any commands it runs.</li> <li>Rinse and repeat.</li> </ol> <p>Example: Text Only<pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py\n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py\n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script:\n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"user-guide/#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several operation to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"user-guide/#choosing-the-provider-and-model","title":"Choosing the provider and model","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider and model you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"user-guide/#additional-features","title":"Additional Features","text":""},{"location":"user-guide/#plugins","title":"Plugins","text":"<p>VMPilot supports various plugins to extend its functionality. See the Plugins documentation for details about available plugins and how to use them.</p> <p>Some key plugins include: - GitHub Issues - Manage GitHub issues directly from VMPilot - Code Map - Generate code documentation automatically</p>"},{"location":"user-guide/#tips-and-best-practices","title":"Tips and Best Practices","text":"<p>For tips on getting the most out of VMPilot, including workspace management, prompt engineering, and general best practices, see our Tips guide.</p>"}]}