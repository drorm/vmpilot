{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VMPilot","text":""},{"location":"#overview","title":"Overview","text":"<p>VMPilot is: - your pair programming partner - virtual machine based: it reads, writes, and performs various actions on files and run commands in the virtual machine. - an agent. It runs multiple commands to perform a task. It\u2019ll for instance run a unit test, see an error, fix it, and keep making changes until there are no errors. - web based with a very advanced and powerful UI curtsy of OpenWebUI. - extensible. Using plugins it targets the full life cycle of software development: creating issues, coding, testing, documenting, etc.</p> <p>[!CAUTION] Only run this if you have enough knowledge about the security implications of running arbitrary commands in your virtual machine. Never run this on your personal machine. You are letting the AI/LLM pilot run commands in your machine and it can be dangerous. Additionally, there is a risk that the AI might interact with the external world, and be taken over by an attacker.</p>"},{"location":"#what-can-you-do-with-vmpilot","title":"What can you do with VMPilot?","text":"<p>Using natural language, you can ask VMPilot to: - Create Github issues - Write and modify code - Create and run tests - Create and update documentation - Manage git repositories - Perform system operations</p>"},{"location":"#features","title":"Features","text":""},{"location":"#core-features","title":"Core Features","text":"<ul> <li>The rich and advanced features of OpenWebUI</li> <li>Code Output Processing Automatic programming language detection,smart code fence wrapping</li> <li>Streaming Support. Support for both streaming and single-response modes</li> <li>Model Support</li> <li>Primarily tested with Claude 3.5 Sonnet</li> <li>OpenAI API gpt4-o support</li> </ul>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation Guide - Complete setup instructions</li> <li>Configuration Guide - Customize your environment</li> <li>User Guide - Learn the basics</li> </ul>"},{"location":"#core-features_1","title":"Core Features","text":"<ul> <li>Command Line Interface - Using the CLI effectively</li> <li>Prompting System - Understanding context management</li> <li>Tips and Best Practices - Optimize your workflow</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>DNS and SSL Setup - Secure access configuration</li> <li>Plugins System - Extend functionality</li> <li>GitHub Issues Integration - Issue management</li> </ul>"},{"location":"cli/","title":"Command Line Interface (CLI)","text":"<p>VMPilot provides a powerful command-line interface that allows you to interact with the tool directly from your terminal.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using the CLI is:</p> Bash<pre><code>cli.sh \"your command here\"\n</code></pre> <p>For example: Bash<pre><code>cli.sh \"Show me the contents of /etc/hosts\"\ncli.sh \"Create a new Python script that prints Hello World\"\ncli.sh  cli.sh  `cat reqeust.sh`\n</code></pre></p> <p>Remember to enclose your command in quotes to ensure that it is passed as a single argument to the CLI. In the last example, we used backticks to execute a command and pass its output as an argument to the CLI.</p>"},{"location":"cli/#command-line-options","title":"Command Line Options","text":"<p>The CLI supports several command line options to customize its behavior:</p> Text Only<pre><code>usage: cli.sh [-h] [-t TEMPERATURE] [-p {anthropic,openai}] [-d] request\n\npositional arguments:\n  request               request to the llm\n\noptions:\n  -h, --help           Show this help message and exit\n  -t TEMPERATURE,      Temperature for response generation (default: 0.7)\n  --temperature\n  -p {anthropic,openai},\n  --provider          API provider to use (default: anthropic)\n  -d, --debug         Enable debug mode\n</code></pre>"},{"location":"cli/#temperature","title":"Temperature","text":"<p>The temperature parameter controls the randomness in the response generation. Higher values (e.g., 0.8) make the output more creative but potentially less focused, while lower values (e.g., 0.2) make it more deterministic and focused. As a rule you should not provide a temperature value, since these are set by the API provider. For testing we use a value of 0 so that the output is deterministic.</p> <p>Example: Bash<pre><code>cli.sh -t 0.3 \"Write a Python function to calculate factorial\"\n</code></pre></p>"},{"location":"cli/#provider-selection","title":"Provider Selection","text":"<p>You can choose between different LLM providers: - anthropic (default) - openai</p> <p>Example: Bash<pre><code>cli.sh -p openai \"Explain how to use the ls command\"\n</code></pre></p>"},{"location":"cli/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode to see detailed logging information, which can be helpful for troubleshooting:</p> Bash<pre><code>cli.sh -d \"Show system information\"\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":"<p>Here are some common usage examples:</p> <ol> <li> <p>Basic system operations: Bash<pre><code>cli.sh \"Show me all Python files in the current directory\"\ncli.sh \"Create a new directory called 'test' and add a README file\"\n</code></pre></p> </li> <li> <p>File editing: Bash<pre><code>cli.sh \"Change the word 'error' to 'warning' in log.txt\"\ncli.sh \"Add a new function to myscript.py\"\n</code></pre></p> </li> <li> <p>Using different providers with custom temperature: Bash<pre><code>cli.sh -p openai -t 0.5 \"Optimize this Python script for performance\"\n</code></pre></p> </li> </ol>"},{"location":"cli/#error-handling","title":"Error Handling","text":"<p>The CLI will display error messages when: - The command execution fails - There are permission issues - The LLM provider is not properly configured - Invalid arguments are provided</p> <p>If you encounter errors, try: 1. Using debug mode (-d) to get more information 2. Checking your API provider configuration 3. Verifying you have the necessary permissions for the requested operation</p>"},{"location":"configuration/","title":"VMPilot Configuration Guide","text":""},{"location":"configuration/#overview","title":"Overview","text":"<p>VMPilot features a flexible configuration system that allows you to customize your environment, LLM providers, and model parameters. This guide explains all available configuration options and how to set them up.</p>"},{"location":"configuration/#configuration-file-priority","title":"Configuration File Priority","text":"<p>VMPilot searches for configuration files in the following order:</p> <ol> <li>Custom path specified in <code>VMPILOT_CONFIG</code> environment variable</li> <li><code>./config.ini</code> in the project directory</li> <li><code>config.ini</code> in the current working directory</li> <li><code>~/.config/vmpilot/config.ini</code></li> </ol> <p>The first configuration file found will be used.</p>"},{"location":"configuration/#configuration-sections","title":"Configuration Sections","text":"<p>The <code>config.ini</code> file is organized into the following sections:</p>"},{"location":"configuration/#general-settings-general","title":"General Settings [general]","text":"Setting Description Default default_provider Primary LLM provider (anthropic/openai) anthropic tool_output_lines Number of lines shown in tool output 15"},{"location":"configuration/#model-settings-model","title":"Model Settings [model]","text":"Setting Description Default recursion_limit Maximum recursive steps allowed 25"},{"location":"configuration/#inference-settings-inference","title":"Inference Settings [inference]","text":"Setting Description Default temperature Model creativity (0.0-1.0) 0.7 max_tokens Maximum response length 2000"},{"location":"configuration/#provider-settings-anthropic-openai","title":"Provider Settings [anthropic] / [openai]","text":"Setting Description Example default_model Default model name claude-3.5 Sonnet api_key_path Path to API key file ~/.anthropic_key api_key_env API key environment variable ANTHROPIC_API_KEY beta_flags Optional beta features (key:value pairs) feature1:on,feature2:off"},{"location":"configuration/#example-configuration","title":"Example Configuration","text":"INI<pre><code>[general]\ndefault_provider = anthropic\ntool_output_lines = 15\n\n[model]\nrecursion_limit = 25\n\n[inference]\ntemperature = 0.7\nmax_tokens = 2000\n\n[anthropic]\ndefault_model = claude-2\napi_key_path = ~/.anthropic_key\napi_key_env = ANTHROPIC_API_KEY\n\n[openai]\ndefault_model = gpt-4\napi_key_path = ~/.openai_key\napi_key_env = OPENAI_API_KEY\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<ul> <li>VMPILOT_CONFIG: Optional path to configuration file</li> <li>Provider-specific API key variables (as specified in config.ini)</li> </ul>"},{"location":"dns_ssl_setup/","title":"DNS and SSL Configuration Guide","text":""},{"location":"dns_ssl_setup/#overview","title":"Overview","text":"<p>This guide covers setting up secure access to your OpenWebUI and VMPilot Pipeline services using DNS and SSL certificates. We'll walk through setting up dynamic DNS and configuring Caddy as a reverse proxy with automatic SSL certificate management. This is optional and not only recommended for secure access to your services, it'll make your life easier to not have to deal with browser warnings about insecure connections.</p> <p>[!CAUTION] While I tried to make this guide somewhat comprehensive, check with Claude or GPT for any additional steps or configurations that might be needed for your specific setup.</p>"},{"location":"dns_ssl_setup/#dynamic-dns-setup","title":"Dynamic DNS Setup","text":"<p>If you're running these services from a location without a static IP which is often the case with home servers, you'll need to set up dynamic DNS to ensure your domain/subdomain always points to the correct IP address.</p> <ol> <li>Choose a Dynamic DNS Provider</li> <li> <p>Options include No-IP, DuckDNS, or Cloudflare</p> </li> <li> <p>Register for Dynamic DNS</p> </li> <li>Create an account at your chosen provider</li> <li>Register your desired subdomain</li> <li> <p>Note down your token/credentials</p> </li> <li> <p>Configure Dynamic DNS Client</p> </li> <li> <p>follow the instructions for your chosen provider</p> </li> <li> <p>Start and Enable the Service</p> </li> </ol>"},{"location":"dns_ssl_setup/#caddy-server-setup","title":"Caddy Server Setup","text":"<p>Caddy is a lightweight web server that can handle automatic SSL certificate management and reverse proxying. We'll use Caddy to set up secure access to OpenWebUI and VMPilot Pipeline.</p> <ol> <li> <p>Install Caddy    Bash<pre><code>sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy\n</code></pre></p> </li> <li> <p>Configure Caddy    Create a Caddyfile:    Bash<pre><code>sudo nano /etc/caddy/Caddyfile\n</code></pre></p> </li> </ol> <p>Basic configuration for OpenWebUI and Pipeline:    Text Only<pre><code>webui.yourdomain.com {\n    reverse_proxy localhost:8080\n}\n\npipeline.yourdomain.com {\n    reverse_proxy localhost:9099\n}\n</code></pre></p> <ol> <li>Start and Enable Caddy    Bash<pre><code>sudo systemctl restart caddy\nsudo systemctl enable caddy\n</code></pre></li> </ol>"},{"location":"dns_ssl_setup/#dns-configuration","title":"DNS Configuration","text":"<ol> <li>Set up A/AAAA Records</li> <li>Point your domain/subdomain to your server's IP</li> <li> <p>If using dynamic DNS, this is handled automatically</p> </li> <li> <p>Verify DNS Propagation    Bash<pre><code>dig webui.yourdomain.com\ndig pipeline.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Check Caddy Status    Bash<pre><code>sudo systemctl status caddy\n</code></pre></p> </li> <li> <p>View Caddy Logs    Bash<pre><code>sudo journalctl -u caddy\n</code></pre></p> </li> <li> <p>Verify SSL Certificates    Bash<pre><code>curl -vI https://webui.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"dns_ssl_setup/#next-steps","title":"Next Steps","text":"<p>Once DNS and SSL are configured, proceed to Installation Guide for setting up OpenWebUI and VMPilot.</p>"},{"location":"github_issues/","title":"GitHub Issues Plugin","text":"<p>The GitHub Issues plugin seamlessly integrates GitHub issue management into VMPilot through the GitHub CLI (<code>gh</code>). This integration allows you to manage GitHub issues using natural language commands without leaving your VMPilot environment. The most valuable use of this plugin is to be able to reference the issues when collaborating with the LLM.</p>"},{"location":"github_issues/#prerequisites","title":"Prerequisites","text":"<p>Before using this plugin, ensure: - GitHub CLI (<code>gh</code>) is installed in the virutal machine - You have completed GitHub CLI authentication (<code>gh auth login</code>)   - Optional, but recommended, create a separate GitHub identity for VMPilot</p>"},{"location":"github_issues/#features","title":"Features","text":""},{"location":"github_issues/#viewing-issues","title":"Viewing Issues","text":"<p>View issues using natural language commands: Text Only<pre><code>show me issue 3\nshow the status of issue #5\nlist all open issues\n</code></pre></p> <p>The plugin handles all necessary steps: 1. Navigates to the project root directory 2. Executes the appropriate GitHub CLI commands 3. Displays formatted issue information</p>"},{"location":"github_issues/#creating-issues","title":"Creating Issues","text":"<p>Create new issues using conversational requests: Text Only<pre><code>create a github issue titled \"Add logging feature\" with label \"enhancement\"\n</code></pre></p> <p>The plugin streamlines the creation process: 1. Follows repository issue templates 2. Collects required information through interactive prompts 3. Creates the issue via GitHub CLI</p>"},{"location":"github_issues/#supported-operations","title":"Supported Operations","text":"<p>The plugin handles essential GitHub issue management: - Viewing issue details - Creating new issues - Listing all issues (open/closed) - Updating issue status - Managing labels and assignments</p>"},{"location":"github_issues/#best-practices","title":"Best Practices","text":"<ol> <li>Clear Communication</li> <li>Use specific, descriptive issue titles</li> <li>Provide detailed descriptions</li> <li> <p>Reference relevant code or documentation</p> </li> <li> <p>Proper Organization</p> </li> <li>Apply appropriate labels</li> <li>Follow repository issue templates</li> <li> <p>Include necessary context</p> </li> <li> <p>Workflow Guidelines</p> </li> <li>Verify issue details before creation</li> <li>Use consistent formatting</li> <li>Follow repository conventions</li> </ol>"},{"location":"github_issues/#examples","title":"Examples","text":""},{"location":"github_issues/#view-an-issue","title":"View an Issue","text":"Text Only<pre><code>show me issue #3\n</code></pre>"},{"location":"github_issues/#create-a-feature-request","title":"Create a Feature Request","text":"Text Only<pre><code>create an issue:\ntitle: Add dark mode support\nlabel: enhancement\ndescription: Implement dark mode theme for better visibility in low-light conditions\n</code></pre>"},{"location":"github_issues/#list-issues","title":"List Issues","text":"Text Only<pre><code>show open issues with label \"bug\"\nlist all issues assigned to me\n</code></pre> <p>The plugin automatically handles the GitHub CLI commands and provides formatted responses for all operations.</p>"},{"location":"github_issues/#technical-implementation","title":"Technical Implementation","text":"<p>The plugin: - Uses the project root as the working directory - Interfaces with GitHub through the CLI - Follows repository-specific templates - Provides interactive feedback - Validates operations before execution</p>"},{"location":"installation/","title":"VMPilot Installation Guide","text":"<p>This guide provides step-by-step instructions for setting up VMPilot in your environment.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have: - Docker container running Ubuntu 22.04 or later - Python 3.11 or later - Basic familiarity with Docker and Linux</p> <p>For secure access setup, we recommend you complete the DNS and SSL Setup before proceeding.</p>"},{"location":"installation/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/#1-virtual-machine-setup","title":"1. Virtual Machine Setup","text":"<ul> <li>Set up your virtual machine according to your requirements</li> <li>For enhanced security, install gvisor and configure your container runtime to use it</li> </ul>"},{"location":"installation/#2-openwebui-installation","title":"2. OpenWebUI Installation","text":"<p>OpenWebUI serves as the frontend interface for VMPilot.</p> <p>Follow the instructions on the OpenWebUI GitHub repository</p> Bash<pre><code>pip install open-webui\n</code></pre> <p>and then run the following command:</p> Bash<pre><code>open-webui serve\n</code></pre> <p>You can, of course, follow one of the other methods suggested in the OpenWebUI documentation.</p>"},{"location":"installation/#31-create-a-new-openwebui-user","title":"3.1 Create a new OpenWebUI user","text":"<p>In a browser, navigate to the OpenWebUI interface at your domain or localhost Create a new user on OpenWebUI which, as the first user, will make you the admin user.</p>"},{"location":"installation/#4-install-openwebui-pipelines","title":"4. Install OpenWebUI Pipelines","text":"<p>OpenWebUI Pipelines is required for VMPilot integration.</p> Bash<pre><code>cd ~\ngit clone https://github.com/open-webui/pipelines\n</code></pre> <p>This will clone the repository to your home directory. This is the default location for VMPilot to look for the pipelines.</p>"},{"location":"installation/#41-install-dependencies","title":"4.1 Install dependencies:","text":"<p>Bash<pre><code>pip install -r requirements.txt\n</code></pre> You don't need to run the pipelines server, as VMPIlot will run it.</p>"},{"location":"installation/#5-installing-vmpilot","title":"5. Installing VMPilot","text":""},{"location":"installation/#51-server-installation","title":"5.1 Server Installation","text":"<p>Clone the VMPilot repository: Bash<pre><code>cd ~\ngit clone https://github.com/yourusername/vmpilot.git\ncd vmpilot\n</code></pre></p> <p>Install dependencies: Bash<pre><code>pip install -r requirements.txt\n</code></pre></p> <p>Set up your credentials. The defaults are: - Anthropic: ~/.anthropic/api_key - OpenAI: ~/.openai</p>"},{"location":"installation/#52-check-the-configuration","title":"5.2 Check the configuration","text":"<p>Look at vmpilot/src/vmpilot/config.ini and make sure the configuration is correct for your setup. Alternatively you can set the environment variable VMPILOT_CONFIG to the path of your configuration file.</p>"},{"location":"installation/#53-start-vmpilot","title":"5.3 Start VMPilot","text":"Bash<pre><code>~/vmpilot/bin/run.sh\n</code></pre>"},{"location":"installation/#32-openwebui-client-configuration","title":"3.2 OpenWebUI Client Configuration","text":"<ol> <li>Access the OpenWebUI interface at your domain or localhost</li> </ol> <p>2 Open OpenWebUI in your browser 2.1 Open OpenWebUI in your browser 2.2 Click on your user name in the bottom left corner 3.3 Click on Admin Panel 3.4 Click on connections</p> <ol> <li>Add VMPilot Connection:</li> <li>URL: http://localhost:9099 and the password</li> <li> <p>Click \"Save\"</p> </li> <li> <p>Enable the pipeline:</p> </li> <li>Go to Pipelines tab</li> <li>Find the above url</li> <li>Enter the keys for the provider you want to use: OpenAI, Anthropic, or both.</li> <li>Click \"Save\"</li> </ol> <p>Note: Because the VMPilot pipeline is a manifold pipeline, you'll see two models in the pipeline list: - VMPilot PipelineAnthropic (Claude) - VMPilot PipelineOpenAI (GPT-4o)</p> <p>Claude is currently the preferred model for VMPilot, since it: - Seems to handle code better. - Is relatively affordable and fast when caching is handled correctly. VMPIlot caches the conversation history, so the model doesn't have to relearn everything every time. - Has been tested more extensively.</p>"},{"location":"installation/#4-verification","title":"4. Verification","text":"<p>To verify your installation:</p> <ol> <li>Open OpenWebUI in your browser. Choose one of the above models and start a conversation.</li> <li>Try a simple command like \"Show me /home\"</li> </ol>"},{"location":"installation/#5-troubleshooting","title":"5 Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Connection refused:</li> <li>Check if VMPilot server is running</li> <li>Verify port configurations</li> <li> <p>Check firewall settings</p> </li> <li> <p>Authentication errors:</p> </li> <li>Verify API key in the UI</li> <li> <p>Check OpenWebUI pipeline configuration</p> </li> <li> <p>Model not found:</p> </li> <li>Go to the connection settings as described above, and save the connection again.</li> <li>Go to the pipeline settings and save the pipeline again.</li> <li>Edit the workplace and make sure the pipeline is selected.</li> </ol>"},{"location":"plugins/","title":"Plugins","text":"<p>VMPilot uses a unique text-based plugin system that extends LLM functionality without requiring traditional code-based implementations. This approach makes plugins easy to add, remove, and maintain.</p>"},{"location":"plugins/#how-plugins-work","title":"How Plugins Work","text":"<p>Instead of using code-based integrations, VMPilot plugins work by injecting the plutin's directory README.md that lists the plugins into the main prompt. When the llm needs to access a plugin, it reads the README.md for that plugin and knows what actions are available.</p> <p>For example, the <code>github_issues</code> plugin enables GitHub issue management through simple text commands. This plugin could be easily replaced with alternatives (like a Jira plugin) by swapping the plugin configuration.</p>"},{"location":"plugins/#current-plugin-system","title":"Current Plugin System","text":"<p>The system currently looks like this: Markdown<pre><code># Available plugins\n\n# Codemap\ndirectory: codemap\nCreates documentation by scanning the code and generating a doc per source file.\n\n# Github\n\ndirectory: github\\_issues\n- To view or list issues, use \"cd $rootDir &amp;&amp; gh issue view $number\" or \"gh issue list\". Always include the \"gh\" command.\n- To create an issue view the README.md file for instructions.\n</code></pre></p>"},{"location":"plugins/#managing-plugins","title":"Managing Plugins","text":"<p>Enabling or disabling plugins is straightforward - simply add or remove their entries from the main README.md file.</p>"},{"location":"plugins/#creating-new-plugins","title":"Creating New Plugins","text":"<p>To create a new plugin: 1. Create a directory in the plugins directory 2. Create a README.md file using template.md from the plugins directory as a guide 3. Add your plugin's entry to the main README.md file in the plugins directory 4. Test the plugin functionality with various prompts</p> <p>For examples of existing plugins, see the <code>codemap</code> and <code>github_issues</code> implementations in the plugins directory.</p>"},{"location":"prompting/","title":"VMPilot Context Management System","text":""},{"location":"prompting/#understanding-vmpilots-approach","title":"Understanding VMPilot's Approach","text":"<p>Whenever you start a conversation with an LLM, it has no context or memory of previous interactions. You need to provide context and direction. VMPilot uses a multi-level prompting system to ensure the LLM has the necessary context to assist effectively.</p>"},{"location":"prompting/#context-layers","title":"Context Layers","text":""},{"location":"prompting/#1-project-context-workspace-level","title":"1. Project Context (Workspace Level)","text":"<p>Managed through OpenWebUI workspaces provide a high-level overview: YAML<pre><code>Essential Components:\n- Project Root Directory: /path/to/project in the vm.\n- Technology Stack: [languages, frameworks, tools]\n- Project Structure: Directory layout and key files\n- Development Guidelines: Coding standards, workflows\n</code></pre></p>"},{"location":"prompting/#2-task-context-github-integration","title":"2. Task Context (GitHub Integration)","text":"<p>Leveraged through the GitHub Issues plugin: YAML<pre><code>Available Information:\n- Issue Details: Requirements, objectives\n- Discussion History: Comments, feedback\n- Project Metadata: Labels, milestones\n- Related Issues: Dependencies, blockers\n</code></pre></p>"},{"location":"prompting/#workspace-management","title":"Workspace Management","text":""},{"location":"prompting/#types-of-workspaces","title":"Types of Workspaces","text":"<p>Organize your development environment with purpose-specific workspaces:</p> <ol> <li> <p>Provider-Specific YAML<pre><code>Examples:\n- OpenAI Development\n- Claude Integration\n- Local Model Testing\n</code></pre></p> </li> <li> <p>Domain-Focused YAML<pre><code>Examples:\n- Frontend Development\n- Backend Services\n- Infrastructure Management\n</code></pre></p> </li> </ol>"},{"location":"prompting/#workspace-setup-guide","title":"Workspace Setup Guide","text":"<ol> <li> <p>Initial Configuration YAML<pre><code>Steps:\n1. Navigate to Workspace Settings\n2. Create New (+) or Edit Existing\n3. Configure Base Settings:\n   - Name: [descriptive identifier]\n   - Model: [preferred LLM]\n   - Temperature: [0.0-1.0]\n</code></pre></p> </li> <li> <p>Context Setup YAML<pre><code>Required Information:\n- Project Directory: Absolute path\n- Stack Definition: Technologies used\n- Access Permissions: Required paths\n- Development Rules: Team guidelines\n</code></pre></p> </li> </ol>"},{"location":"prompting/#using-github-integration","title":"Using GitHub Integration","text":"<p>Access issue context with simple commands to the llm: Markdown<pre><code># View specific issue\nLook at github issue 42\n\n# List recent issues\nShow open issues\n\n# Reference in discussion\nRegarding issue 42, can we...\n</code></pre></p>"},{"location":"prompting/#example-vmpilot-development-prompt","title":"Example: VMPilot Development Prompt","text":"<p>Below is the actual prompt used in VMPilot's development:</p> Markdown<pre><code># Project Overview: VMPilot\nAn AI-driven system operations assistant with CLI and API interfaces.\n\n## Location and structure\n\nThe base directory is $HOME/vmpilot.  Always **cd to this directory** before looking at the files.\n\n```bash\ncd $HOME/vmpilot &amp;&amp; ls\n```\n\n\nIgnore directories not listed below.\n\n\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 source -- Documentation source files\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 user-guide\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 vmpilot -- Main source code directory\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 caching\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 plugins\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 codemap\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 github_issues\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 tools -- Llm Tool implementations\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 scripts -- Integration test scripts\n    \u251c\u2500\u2500 sample_files -- file used by tests\n    \u2514\u2500\u2500 unit -- Unit tests\n        \u2514\u2500\u2500 tools\n\n\n## Architecture\n* Supports multiple deployment modes:\n  - CLI mode (vmpilot-cli)\n  - Pipeline mode (OpenWebUI compatible, port 9099)\n\n## Development Guidelines\n* Tools follow standard interface with required methods\n* Pipeline integrates with OpenWebUI specification\n\n#### /src/vmpilot/\nMain source code directory containing the core implementation.\n- **Core Files**:\n  - vmpilot.py: Main application entry point. Implements the Pipeline mode.\n  - agent.py: Core implementation for the agent\n    - Handles LLM setup and configuration\n    - Implements message processing pipeline\n    - Manages tool integration\n  - config.py: Configuration management\n  - cli.py: Command-line interface implementation\n\n#### /src/vmpilot/tools/\nTool implementations for various functionalities.\n  - CreateFileTool: Create a file\n  - EditTool: Edit a file\n  - SetupShellTool: shell tool\n\n#### /bin/\nExecution scripts:\n- cli.sh: CLI launcher\n- run.sh: Main execution script for the openwebui pipeline\n\n#### /tests/\nTest suite and testing utilities:\n- Test harnesses\n- Sample files\n- Integration tests\n\n## Key Features\n\n1. **LLM Integration**\n   - Supports multiple providers (Anthropic, OpenAI)\n   - Configurable models and parameters\n   - Streaming response capability\n\n2. **Tool System**\n   - Extensible tool framework\n   - Built-in file and system operations\n   - Error handling and result management\n\n3. **Pipeline Architecture**\n   - Message processing pipeline\n   - Asynchronous operation support\n   - State management and checkpointing\n\n4. **Development Tools**\n   - Comprehensive testing framework\n   - Deployment automation\n   - Development utilities\n\n## Testing and Development\n- Structured test suite in /tests\n- Integration test scripts\n- Sample files for testing\n\n## Common Usage Patterns\n### CLI Mode\n- cli.sh \"Show me /home\"\n- cli \"create a hello world example in /tmp/hello.py\"\n</code></pre>"},{"location":"prompting/#github-issues-as-prompts","title":"Github issues as prompts","text":"<p>To provide context about the current task, we use the <code>github issues</code> plugin.  Just ask the llm to view the issue, and it will provide the context.</p>"},{"location":"prompting/#example","title":"Example","text":"<p>When working on the VMPilot docs, I ask:</p> <p>Markdown<pre><code>Look at github issue 3, documentation.\n\n    I added a new section \u201cPrompting\u201d. I\u2019m concerned, however that experienced users will skip it because they know how to prompt. However, this page has some important info about prompting in vmpilot\n</code></pre> And the llm responds: Markdown<pre><code>I'll help analyze these points. Let me first look at issue 3 and the documentation.\n```\n$ cd /home/dror/vmpilot &amp;&amp; gh issue view 3\ntitle:  Documentation System Setup with MkDocs and GitHub Pages\nstate:  OPEN\nauthor: dror-llm\nlabels: documentation, enhancement\ncomments:   2\nassignees:  drorm\nprojects:\nmilestone:  0.1\nnumber: 3\n--\n# Documentation System Setup with MkDocs and GitHub Pages\n...\n(and 64 more lines)\nLet me address each of your points:\n\n    Regarding the \"Prompting\" section concern:\n            You're right that this is a valid concern. Since VMPilot has specific prompting requirements/features, I suggest renaming it to something more specific like \"VMPilot-Specific Prompting\" or \"VMPilot Prompt System\" to differentiate it from general LLM prompting. This makes it clear that even experienced prompt engineers should read it.\n</code></pre></p>"},{"location":"tips/","title":"VMPilot Best Practices Guide","text":""},{"location":"tips/#getting-started","title":"Getting Started","text":""},{"location":"tips/#api-key-management","title":"API Key Management","text":"<p>For optimal cost control and usage tracking: 1. Create a dedicated API key for VMPilot 2. Set specific budget limits 3. Monitor usage separately from other API applications 4. Regularly review consumption patterns</p>"},{"location":"tips/#effective-communication","title":"Effective Communication","text":""},{"location":"tips/#managing-conversations","title":"Managing Conversations","text":"<p>Long conversations can reduce effectiveness. To maintain quality: 1. Keep conversations focused on specific tasks 2. Start new sessions for new topics 3. Include relevant context when starting fresh 4. Save important snippets for future reference</p>"},{"location":"tips/#task-management","title":"Task Management","text":"<p>Break down complex tasks: - Divide large tasks into smaller, manageable steps - Verify each step before proceeding - Combine manual work with LLM assistance when needed</p>"},{"location":"tips/#using-openwebui","title":"Using OpenWebUI","text":""},{"location":"tips/#using-workspaces","title":"Using Workspaces","text":"<p>Workspaces are powerful organizational tools that allow you to group related pipelines and prompts. Here are some example workspace categories: - My software with OpenAI - My software with Anthropic - Frontend development - Backend development - Personal</p> <p>When setting up a workspace prompt, include: - The root directory of your project (crucial for file operations) - Your technology stack - A brief project description and file structure overview</p>"},{"location":"tips/#creating-a-workspace","title":"Creating a Workspace","text":"<ol> <li>Click on \"Workspace\"</li> <li>Click the \"+\" button to create a new workspace</li> <li>Enter a name and configure the prompt and settings</li> <li>Click \"Save\"</li> </ol>"},{"location":"tips/#llm-error-handling","title":"LLM Error Handling","text":"<p>The LLM may run into issues when using tools. You'll see errors like: - \"Field required [type=missing, input_value={}, input_type=dict]\" - \"messages.1.content.1.tool_use.name: String should match pattern '^[a-zA-Z0-9_-]{1,64}$'\"}\" - \"messages.5.content.1.tool_use.name: String should have at most 64 characters'}}\"</p> <p>This mostly happens when the LLM tries to edit a file with a large amount of content. To resolve this try: - Ask the llm to create a new file instead of editing a new - Start a new shorter conversation - Break down the task into smaller steps</p> <p>This is an ongoing issue with LLMs and hopefully will get better with time. We're also working on improving the error handling and recovery mechanisms.</p>"},{"location":"tips/#why-this-happens","title":"Why This Happens","text":""},{"location":"tips/#edit-your-prompt","title":"Edit your prompt","text":"<p>When you're working on a prompt, it's often helpful to edit the original or latest prompt to refine your request. This can help you get more accurate and relevant responses from the LLM.</p>"},{"location":"tips/#stop-the-llm","title":"Stop the LLM","text":"<p>Sometimes the LLM may get stuck or go in the wrong direction. Hit the \"Stop\" button to reset the LLM and start fresh.</p>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#introduction","title":"Introduction","text":"<p>VMpilot is a powerful tool that enables collaboration with Large Language Models (LLMs) in a virtual machine environment. While primarily designed for software development tasks, it can be utilized for any operation that benefits from LLM assistance in a VM context.</p>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<p>VMPilot comes with three core tools out of the box: 1. Shell Tool: Executes shell commands and scripts 2. File Editing Tool: Modifies existing files 3. File Creation Tool: Creates new files with specified content</p>"},{"location":"user-guide/#security-note","title":"Security Note","text":"<p>[!CAUTION] VMPilot operates with your user permissions. The LLM can execute any command available to your user account, including: - Reading and writing files - Installing packages - Running system commands</p> <p>Always ensure you only grant access to directories and permissions you trust the LLM to handle.</p>"},{"location":"user-guide/#typical-operation","title":"Typical operation","text":"<ol> <li>Start a new conversation in the OpenWebUI interface</li> <li>Describe the task you want the LLM to perform.</li> <li>The LLM performs the task and provides the output of any commands it runs.</li> <li>Rinse and repeat.</li> </ol> <p>Example: Text Only<pre><code>user: create a hello world example in /tmp\nclaude-VMPilot:\nI'll help you create a simple \"Hello, World!\" program. Since the request is to create a file but doesn't specify the exact filename, I'll create a Python file named hello.py in the /tmp directory.I've created a simple Python \"Hello, World!\" program in /tmp/hello.py. Let's verify the file was created and check its contents:\n$ cat /tmp/hello.py\n'''python\n#!/usr/bin/env python3\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nLet's make the script executable and run it to make sure it works:\n$ chmod +x /tmp/hello.py &amp;&amp; /tmp/hello.py\n'''bash\nHello, World!\n```\n\nThe program has been created successfully and works as expected! The script:\n\n1. Is located at /tmp/hello.py\n1. Has proper Python shebang line\n1. Uses a main() function with the standard name  check\n1. Successfully prints \"Hello, World!\" when executed\n</code></pre></p>"},{"location":"user-guide/#notes","title":"Notes","text":"<ul> <li> <p>The LLM tends to be a bit verbose and has a bias towards action. It will, as is often the case with LLMs, try its best to answer your question, or perform the task you've asked it to do, rather than ask for clarification. You can change that by asking it to just discuss the task or ask for clarification.</p> </li> <li> <p>It can perform several operation to accomplish a task. In our case, it created the script, and ran it to verify that it works.</p> </li> <li> <p>Outputs are fenced in the appropriate language for easy reading.</p> </li> <li> <p>The LLM will often provide additional information about the task it performed, such as the location of the file it created, the contents of the file, and the output of any commands it ran.</p> </li> </ul>"},{"location":"user-guide/#choosing-the-provider","title":"Choosing the provider","text":"<p>We support multiple providers such as OpenAI and Anthropic. You can choose the provider you want to use in the OpenWebUI interface on the top left. This is quite similar to how you would choose a model in OpenAI's interface. We recommend however that you use Workspaces since they allow you to both choose the model and prompt you want to use.</p>"},{"location":"user-guide/#additional-features","title":"Additional Features","text":""},{"location":"user-guide/#plugins","title":"Plugins","text":"<p>VMPilot supports various plugins to extend its functionality. See the Plugins documentation for details about available plugins and how to use them.</p> <p>Some key plugins include:</p> <ul> <li>GitHub Issues - Manage GitHub issues directly from VMPilot</li> <li>Code Map - Generate code documentation automatically. This is a work in progress.</li> </ul>"},{"location":"user-guide/#tips-and-best-practices","title":"Tips and Best Practices","text":"<p>For tips on getting the most out of VMPilot, including workspace management, prompt engineering, and general best practices, see our Tips guide.</p>"}]}